{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b5c0d2440b3e4995a794ded565213150","deepnote_cell_type":"markdown"},"source":["<h1><center>Laboratorio 9: Optimizaci칩n de modelos 游눮</center></h1>\n","\n","<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos</strong></center>"]},{"cell_type":"markdown","metadata":{"cell_id":"bfb94b9656f145ad83e81b75d218cb70","deepnote_cell_type":"markdown"},"source":["### Cuerpo Docente:\n","\n","- Profesor: Ignacio Meza, Gabriel Iturra\n","- Auxiliar: Sebasti치n Tinoco\n","- Ayudante: Arturo Lazcano, Angelo Mu침oz"]},{"cell_type":"markdown","metadata":{"cell_id":"b1b537fdd27c43909a49d3476ce64d91","deepnote_cell_type":"markdown"},"source":["### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n","\n","- Nombre de alumno 1: Tom치s Aguirre\n","- Nombre de alumno 2: Ignacio Albornoz\n"]},{"cell_type":"markdown","metadata":{"cell_id":"b7dbdd30ab544cb8a8afe00648a586ae","deepnote_cell_type":"markdown"},"source":["## Temas a tratar\n","\n","- Predicci칩n de demanda usando `xgboost`\n","- B칰squeda del modelo 칩ptimo de clasificaci칩n usando `optuna`\n","- Uso de pipelines.\n","\n","## Reglas:\n","\n","- **Grupos de 2 personas**\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n","- Prohibidas las copias. \n","- Pueden usar cualquer material del curso que estimen conveniente.\n","\n","### Objetivos principales del laboratorio\n","\n","- Optimizar modelos usando `optuna`\n","- Recurrir a t칠cnicas de *prunning*\n","- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n","- Fijar un pipeline con un modelo base que luego se ir치 optimizando.\n","\n","El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."]},{"cell_type":"markdown","metadata":{"cell_id":"f38c8342f5164aa992a97488dd5590bf","deepnote_cell_type":"markdown"},"source":["### **Link de repositorio de GitHub:** `https://github.com/tomasaguirre-ignacioalbornoz/MDS7202`"]},{"cell_type":"markdown","metadata":{"cell_id":"f1c73babb7f74af588a4fa6ae14829e0","deepnote_cell_type":"markdown"},"source":["# Importamos librerias 칰tiles"]},{"cell_type":"code","execution_count":12,"metadata":{"cell_id":"51afe4d2df42442b9e5402ffece60ead","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4957,"execution_start":1699544354044,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: joblib in c:\\users\\tomas\\anaconda3\\envs\\lab_6\\lib\\site-packages (1.3.2)\n"]}],"source":["!pip install -qq xgboost optuna\n","!pip install joblib"]},{"cell_type":"markdown","metadata":{"cell_id":"44d227389a734ac59189c5e0005bc68a","deepnote_cell_type":"markdown"},"source":["# 1. El emprendimiento de Fiu\n","\n","Tras liderar de manera exitosa la implementaci칩n de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corp칩reo **Fiu** se anima y decide levantar su propio negocio de consultor칤a en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Como usted tuvo un rendimiento sobresaliente en el proyecto de caracterizaci칩n de datos, Fiu lo contrata como *data scientist* de su emprendimiento.\n","\n","Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n","\n","Para comenzar, cargue el dataset se침alado y visualice a trav칠s de un `.head` los atributos que posee el dataset.\n","\n","<i><p align=\"center\">Fiu siendo felicitado por su excelente desempe침o en el proyecto de caracterizaci칩n de datos</p></i>\n","<p align=\"center\">\n","  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n","</p>"]},{"cell_type":"code","execution_count":13,"metadata":{"cell_id":"2f9c82d204b14515ad27ae07e0b77702","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":92,"execution_start":1699544359006,"source_hash":null},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>date</th>\n","      <th>city</th>\n","      <th>lat</th>\n","      <th>long</th>\n","      <th>pop</th>\n","      <th>shop</th>\n","      <th>brand</th>\n","      <th>container</th>\n","      <th>capacity</th>\n","      <th>price</th>\n","      <th>quantity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>0.96</td>\n","      <td>13280</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>plastic</td>\n","      <td>1.5lt</td>\n","      <td>2.86</td>\n","      <td>6727</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>can</td>\n","      <td>330ml</td>\n","      <td>0.87</td>\n","      <td>9848</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>adult-cola</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>1.00</td>\n","      <td>20050</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>adult-cola</td>\n","      <td>can</td>\n","      <td>330ml</td>\n","      <td>0.39</td>\n","      <td>25696</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id       date    city       lat      long     pop    shop        brand  \\\n","0   0 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","1   1 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","2   2 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","3   3 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n","4   4 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n","\n","  container capacity  price  quantity  \n","0     glass    500ml   0.96     13280  \n","1   plastic    1.5lt   2.86      6727  \n","2       can    330ml   0.87      9848  \n","3     glass    500ml   1.00     20050  \n","4       can    330ml   0.39     25696  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","\n","df = pd.read_csv('sales.csv')\n","df['date'] = pd.to_datetime(df['date'], format='%d/%m/%y')\n","\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"cell_id":"b50db6f2cb804932ae3f9e5748a6ea61","deepnote_cell_type":"markdown"},"source":["## 1.1 Generando un Baseline (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n","</p>\n","\n","Antes de entrenar un algoritmo, usted recuerda los apuntes de su mag칤ster en ciencia de datos y recuerda que debe seguir una serie de *buenas pr치cticas* para entrenar correcta y debidamente su modelo. Despu칠s de un par de vueltas, llega a las siguientes tareas:\n","\n","1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad.\n","2. Implemente un `FunctionTransformer` para extraer el d칤a, mes y a침o de la variable `date`. Guarde estas variables en el formato categorical de pandas.\n","3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos num칠ricos y categ칩ricos. Use `OneHotEncoder` para las variables categ칩ricas.\n","4. Guarde los pasos anteriores en un `Pipeline`, dejando como 칰ltimo paso el regresor `DummyRegressor` para generar predicciones en base a promedios.\n","5. Entrene el pipeline anterior y reporte la m칠trica `mean_absolute_error` sobre los datos de validaci칩n. 쮺칩mo se interpreta esta m칠trica para el contexto del negocio?\n","6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los par치metros por default**. 쮺칩mo cambia el MAE al implementar este algoritmo? 쮼s mejor o peor que el `DummyRegressor`?\n","7. Guarde ambos modelos en un archivo .pkl (uno cada uno)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   id    city       lat      long     pop    shop        brand container  \\\n","0   0  Athens  37.97945  23.71622  672130  shop_1  kinder-cola     glass   \n","1   1  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   plastic   \n","2   2  Athens  37.97945  23.71622  672130  shop_1  kinder-cola       can   \n","3   3  Athens  37.97945  23.71622  672130  shop_1   adult-cola     glass   \n","4   4  Athens  37.97945  23.71622  672130  shop_1   adult-cola       can   \n","\n","  capacity  price  quantity day month  year  \n","0    500ml   0.96     13280  31     1  2012  \n","1    1.5lt   2.86      6727  31     1  2012  \n","2    330ml   0.87      9848  31     1  2012  \n","3    500ml   1.00     20050  31     1  2012  \n","4    330ml   0.39     25696  31     1  2012  \n","numeric_features\n","Index(['id', 'lat', 'long', 'pop', 'price'], dtype='object')\n","categorical_features\n","['day', 'month', 'year', 'city', 'shop', 'brand', 'container', 'capacity', 'day', 'month', 'year']\n","Index(['id', 'date', 'city', 'lat', 'long', 'pop', 'shop', 'brand',\n","       'container', 'capacity', 'price'],\n","      dtype='object')\n","MAE con DummyRegressor: 13298.497767341096\n","MAE con XGBRegressor: 2418.5801385461205\n"]},{"data":{"text/plain":["['model_xgb.pkl']"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Importar librer칤as necesarias\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.dummy import DummyRegressor\n","from sklearn.metrics import mean_absolute_error\n","from xgboost import XGBRegressor\n","import joblib\n","\n","\n","# Separar en conjuntos de train, validation y test\n","train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n","val_df, test_df = train_test_split(temp_df, test_size=(1/3), random_state=42)\n","\n","# Crear un FunctionTransformer para extraer d칤a, mes y a침o\n","def extract_date_parts(df):\n","    df['day'] = df['date'].dt.day.astype('category')\n","    df['month'] = df['date'].dt.month.astype('category')\n","    df['year'] = df['date'].dt.year.astype('category')\n","    df = df.drop(columns=['date'])\n","    return df\n","\n","print(extract_date_parts(df).head())\n","\n","date_transformer = FunctionTransformer(extract_date_parts, validate=False)\n","\n","# Crear un ColumnTransformer para procesar los datos\n","#numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n","\n","numeric_features = df.select_dtypes(include=['int64', 'float64']).drop('quantity', axis=1).columns\n","\n","\n","# Lista inicial de caracter칤sticas categ칩ricas\n","categorical_features = ['day', 'month', 'year']\n","\n","# A침adir columnas del DataFrame que no son de tipo int64 o float64\n","categorical_features.extend(df.select_dtypes(exclude=['int64', 'float64']).columns)\n","\n","# Excluir la columna 'date'\n","categorical_features.remove('date')\n","\n","print(\"numeric_features\")\n","print(numeric_features)\n","print(\"categorical_features\")\n","print(categorical_features)\n","\n","# Creando un dataframe que solo contiene la columna 'quantity'\n","train_Y = train_df[['quantity']]\n","\n","# Creando otro dataframe que contiene todas las columnas excepto 'quantity'\n","train_X = train_df.drop(columns=['quantity'])\n","\n","print(train_X.columns)\n","\n","# Creando un dataframe que solo contiene la columna 'quantity'\n","test_Y = test_df[['quantity']]\n","\n","# Creando otro dataframe que contiene todas las columnas excepto 'quantity'\n","test_X = test_df.drop(columns=['quantity'])\n","\n","# Creando un dataframe que solo contiene la columna 'quantity'\n","val_Y= val_df[['quantity']]\n","\n","# Creando otro dataframe que contiene todas las columnas excepto 'quantity'\n","val_X = val_df.drop(columns=['quantity'])\n","\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', 'passthrough', numeric_features),\n","        ('cat', OneHotEncoder(), categorical_features)\n","    ])\n","\n","# Crear y entrenar el pipeline con DummyRegressor\n","pipeline_dummy = Pipeline(steps=[\n","    ('date', date_transformer),\n","    ('preprocessor', preprocessor),\n","    ('regressor', DummyRegressor(strategy='mean'))\n","])\n","\n","\n","#print(\"debug1\")\n","pipeline_dummy.fit(train_X, train_Y) \n","\n","# Evaluar el modelo\n","y_pred = pipeline_dummy.predict(val_X)\n","\n","mae_dummy = mean_absolute_error(val_Y, y_pred)\n","print(f'MAE con DummyRegressor: {mae_dummy}')\n","\n","\n","# Reemplazar DummyRegressor con XGBRegressor y entrenar nuevamente\n","pipeline_xgb = Pipeline(steps=[\n","    ('date', date_transformer),\n","    ('preprocessor', preprocessor),\n","    ('regressor', XGBRegressor())\n","])\n","\n","pipeline_xgb.fit(train_X, train_Y) \n","\n","# Evaluar el nuevo modelo\n","y_pred_xgb = pipeline_xgb.predict(val_X)\n","mae_xgb = mean_absolute_error(val_Y, y_pred_xgb)\n","print(f'MAE con XGBRegressor: {mae_xgb}')\n","\n","# Guardar los modelos\n","joblib.dump(pipeline_dummy, 'model_dummy.pkl')\n","joblib.dump(pipeline_xgb, 'model_xgb.pkl')\n"]},{"cell_type":"markdown","metadata":{"cell_id":"7e17e46063774ec28226fe300d42ffe0","deepnote_cell_type":"markdown"},"source":["## 1.2 Forzando relaciones entre par치metros con XGBoost (1.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n","</p>\n","\n","Un colega aficionado a la econom칤a le *sopla* que la demanda guarda una relaci칩n inversa con el precio del producto. Motivado para impresionar al querido corp칩reo, se propone hacer uso de esta informaci칩n para mejorar su modelo.\n","\n","Vuelva a entrenar el `Pipeline`, pero esta vez forzando una relaci칩n mon칩tona negativa entre el precio y la cantidad. Luego, vuelva a reportar el `MAE` sobre el conjunto de validaci칩n. 쮺칩mo cambia el error al incluir esta relaci칩n? 쯊en칤a raz칩n su amigo?\n","\n","Nuevamente, guarde su modelo en un archivo .pkl\n","\n","Nota: Para realizar esta parte, debe apoyarse en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentaci칩n</a>.\n","\n","Hint: Para implementar el constraint, se le sugiere hacerlo especificando el nombre de la variable. De ser as칤, probablemente le sea 칰til **mantener el formato de pandas** antes del step de entrenamiento."]},{"cell_type":"code","execution_count":16,"metadata":{"cell_id":"f469f3b572be434191d2d5c3f11b20d2","deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE con XGBRegressor y constraint mon칩tono: 2459.1016334006645\n"]},{"data":{"text/plain":["['model_xgb_monotone.pkl']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Crear una lista con 'price' como el primer elemento seguido por el resto de las columnas\n","ordered_columns = ['price'] + [col for col in train_X.columns if col != 'price']\n","\n","# Reordenar las columnas en los DataFrames\n","train_X_reordered = train_X[ordered_columns]\n","val_X_reordered = val_X[ordered_columns]\n","#test_X_reordered = test_X[ordered_columns]\n","\n","# Definir los constraints de monoton칤a\n","# Asumiendo que 'price' es la primera columna despu칠s del preprocesamiento\n","# -1 indica una relaci칩n mon칩tona negativa\n","monotone_constraints = (-1,)\n","'''\n","from scipy.sparse import issparse\n","\n","class DataInspector(BaseEstimator, TransformerMixin):\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        # Verificar si X es una matriz dispersa\n","        if issparse(X):\n","            # Convertir a DataFrame para visualizaci칩n si es matriz dispersa\n","            X_dense = X.todense()\n","            print(pd.DataFrame(X_dense).head())\n","        else:\n","            # Imprimir las primeras filas del DataFrame\n","            print(X.head())\n","        return X\n","'''\n","# Incluir el inspector de datos en el pipeline antes del regresor\n","pipeline_xgb_monotone = Pipeline(steps=[\n","    ('date', date_transformer),\n","    ('preprocessor', preprocessor),\n","    #('inspector', DataInspector()),  # Paso de inspecci칩n agregado aqu칤\n","    ('regressor', XGBRegressor(monotone_constraints=monotone_constraints))\n","])\n","\n","\n","pipeline_xgb_monotone.fit(train_X_reordered, train_Y)\n","\n","# Evaluar el modelo\n","y_pred_xgb_monotone = pipeline_xgb_monotone.predict(val_X_reordered)\n","mae_xgb_monotone = mean_absolute_error(val_Y, y_pred_xgb_monotone)\n","print(f'MAE con XGBRegressor y constraint mon칩tono: {mae_xgb_monotone}')\n","\n","# Guardar el modelo\n","joblib.dump(pipeline_xgb_monotone, 'model_xgb_monotone.pkl')\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"e59ef80ed20b4de8921f24da74e87374","deepnote_cell_type":"markdown"},"source":["## 1.3 Optimizaci칩n de Hiperpar치metros con Optuna (2.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n","</p>\n","\n","Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun m치s* su modelo. En particular, le comenta de la optimizaci칩n de hiperpar치metros con metodolog칤as bayesianas a trav칠s del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n","\n","A partir de la mejor configuraci칩n obtenida en la secci칩n anterior, utilice `optuna` para optimizar sus hiperpar치metros. En particular, se le pide:\n","\n","- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n","- Utilice `TPESampler` como m칠todo de muestreo\n","- De `XGBRegressor`, optimice los siguientes hiperpar치metros:\n","    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n","    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n","    - `max_depth` buscando valores enteros en el rango (3, 10)\n","    - `max_leaves` buscando valores enteros en el rango (0, 100)\n","    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n","    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n","    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n","- De `OneHotEncoder`, optimice el hiperpar치metro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n","- Explique cada hiperpar치metro y su rol en el modelo. 쮿acen sentido los rangos de optimizaci칩n indicados?\n","- Fije el tiempo de entrenamiento a 5 minutos\n","- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto?\n","- Guardar su modelo en un archivo .pkl"]},{"cell_type":"code","execution_count":18,"metadata":{"cell_id":"de5914621cc64cb0b1bacb9ff565a97e","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-11-13 12:34:44,558] A new study created in memory with name: no-name-41ceacde-e8f2-405f-b541-2b0477b9c28d\n","[I 2023-11-13 12:34:49,531] Trial 0 finished with value: 2726.9488765273936 and parameters: {'learning_rate': 0.08197440749175473, 'n_estimators': 574, 'max_depth': 6, 'max_leaves': 9, 'min_child_weight': 5, 'reg_alpha': 0.9673564038996015, 'reg_lambda': 0.09820669376309132, 'min_frequency': 0.8018603712796477}. Best is trial 0 with value: 2726.9488765273936.\n","[I 2023-11-13 12:34:56,268] Trial 1 finished with value: 2203.2271025239984 and parameters: {'learning_rate': 0.060885309625463256, 'n_estimators': 606, 'max_depth': 6, 'max_leaves': 48, 'min_child_weight': 2, 'reg_alpha': 0.30960447319461515, 'reg_lambda': 0.9079540077466299, 'min_frequency': 0.18498483412439337}. Best is trial 1 with value: 2203.2271025239984.\n","[I 2023-11-13 12:34:58,048] Trial 2 finished with value: 4504.880091748407 and parameters: {'learning_rate': 0.019635701927839904, 'n_estimators': 134, 'max_depth': 9, 'max_leaves': 64, 'min_child_weight': 5, 'reg_alpha': 0.5330602987538661, 'reg_lambda': 0.8794020557461902, 'min_frequency': 0.2934004821510383}. Best is trial 1 with value: 2203.2271025239984.\n","[I 2023-11-13 12:35:01,566] Trial 3 finished with value: 3047.6369158554844 and parameters: {'learning_rate': 0.043355733720661614, 'n_estimators': 707, 'max_depth': 3, 'max_leaves': 13, 'min_child_weight': 2, 'reg_alpha': 0.6820953023813442, 'reg_lambda': 0.9639243986805761, 'min_frequency': 0.45409686805072225}. Best is trial 1 with value: 2203.2271025239984.\n","[I 2023-11-13 12:35:04,941] Trial 4 finished with value: 2652.058607913759 and parameters: {'learning_rate': 0.05170504867584292, 'n_estimators': 492, 'max_depth': 4, 'max_leaves': 20, 'min_child_weight': 2, 'reg_alpha': 0.3327931153595155, 'reg_lambda': 0.6910206996195489, 'min_frequency': 0.2804722556853273}. Best is trial 1 with value: 2203.2271025239984.\n","[I 2023-11-13 12:35:06,374] Trial 5 finished with value: 2876.099084333475 and parameters: {'learning_rate': 0.08276584689647232, 'n_estimators': 210, 'max_depth': 4, 'max_leaves': 78, 'min_child_weight': 2, 'reg_alpha': 0.6303835630942795, 'reg_lambda': 0.9460455286194741, 'min_frequency': 0.26344784197778537}. Best is trial 1 with value: 2203.2271025239984.\n","[I 2023-11-13 12:35:15,218] Trial 6 finished with value: 2331.18687270105 and parameters: {'learning_rate': 0.025410502155778256, 'n_estimators': 840, 'max_depth': 8, 'max_leaves': 36, 'min_child_weight': 5, 'reg_alpha': 0.969745948955058, 'reg_lambda': 0.8435000420609184, 'min_frequency': 0.5492408554174478}. Best is trial 1 with value: 2203.2271025239984.\n","[I 2023-11-13 12:35:22,443] Trial 7 finished with value: 2167.6634915285986 and parameters: {'learning_rate': 0.06294703589733973, 'n_estimators': 530, 'max_depth': 9, 'max_leaves': 57, 'min_child_weight': 1, 'reg_alpha': 0.10524252085818897, 'reg_lambda': 0.8391481353085176, 'min_frequency': 0.8865100631109258}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:35:28,074] Trial 8 finished with value: 2267.287744861094 and parameters: {'learning_rate': 0.0964798633537203, 'n_estimators': 532, 'max_depth': 5, 'max_leaves': 73, 'min_child_weight': 5, 'reg_alpha': 0.3825242291436415, 'reg_lambda': 0.5951412356839362, 'min_frequency': 0.14260148902509284}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:35:32,851] Trial 9 finished with value: 2400.609990836949 and parameters: {'learning_rate': 0.08570184631980145, 'n_estimators': 559, 'max_depth': 4, 'max_leaves': 15, 'min_child_weight': 1, 'reg_alpha': 0.9790200997396965, 'reg_lambda': 0.36526623202322483, 'min_frequency': 0.925974139577977}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:35:49,785] Trial 10 finished with value: 2399.388732951092 and parameters: {'learning_rate': 0.01020312221263825, 'n_estimators': 979, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 1, 'reg_alpha': 0.022071705722580423, 'reg_lambda': 0.47362280996087375, 'min_frequency': 0.9926488225967768}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:35:53,514] Trial 11 finished with value: 2282.4561241144784 and parameters: {'learning_rate': 0.0620144434328995, 'n_estimators': 318, 'max_depth': 7, 'max_leaves': 47, 'min_child_weight': 3, 'reg_alpha': 0.10593191148595449, 'reg_lambda': 0.7465817311240537, 'min_frequency': 0.03146823557118361}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:35:58,245] Trial 12 finished with value: 2194.5042034433163 and parameters: {'learning_rate': 0.06605638031184853, 'n_estimators': 357, 'max_depth': 7, 'max_leaves': 52, 'min_child_weight': 3, 'reg_alpha': 0.16856776286176567, 'reg_lambda': 0.9767370780921074, 'min_frequency': 0.7232843385678996}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:36:02,397] Trial 13 finished with value: 2339.072782888739 and parameters: {'learning_rate': 0.06509926746123812, 'n_estimators': 358, 'max_depth': 8, 'max_leaves': 32, 'min_child_weight': 4, 'reg_alpha': 0.18860140196096267, 'reg_lambda': 0.7249286936835985, 'min_frequency': 0.7473384486215272}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:36:08,286] Trial 14 finished with value: 2291.2278803026493 and parameters: {'learning_rate': 0.04241145243072532, 'n_estimators': 363, 'max_depth': 10, 'max_leaves': 62, 'min_child_weight': 3, 'reg_alpha': 0.01454634976974406, 'reg_lambda': 0.796061863457112, 'min_frequency': 0.7136072721006441}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:36:09,561] Trial 15 finished with value: 2775.812707462221 and parameters: {'learning_rate': 0.07373638684673287, 'n_estimators': 79, 'max_depth': 8, 'max_leaves': 87, 'min_child_weight': 4, 'reg_alpha': 0.17160789126820541, 'reg_lambda': 0.9214076199409373, 'min_frequency': 0.8525221366479201}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:36:15,908] Trial 16 finished with value: 2213.826502963091 and parameters: {'learning_rate': 0.07098253704603237, 'n_estimators': 419, 'max_depth': 7, 'max_leaves': 56, 'min_child_weight': 1, 'reg_alpha': 0.2217740360840028, 'reg_lambda': 0.9855347094645254, 'min_frequency': 0.6614994434391703}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:36:26,592] Trial 17 finished with value: 2226.3380571515027 and parameters: {'learning_rate': 0.05442748572340318, 'n_estimators': 728, 'max_depth': 9, 'max_leaves': 38, 'min_child_weight': 4, 'reg_alpha': 0.10827638286519292, 'reg_lambda': 0.8177646816101791, 'min_frequency': 0.8718868598280651}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:36:30,921] Trial 18 finished with value: 2337.4035380905225 and parameters: {'learning_rate': 0.04013814619308147, 'n_estimators': 201, 'max_depth': 9, 'max_leaves': 0, 'min_child_weight': 3, 'reg_alpha': 0.00999081676759278, 'reg_lambda': 0.6430337575423195, 'min_frequency': 0.9935827608560953}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:36:34,646] Trial 19 finished with value: 2207.6629493759433 and parameters: {'learning_rate': 0.0996515795171467, 'n_estimators': 251, 'max_depth': 7, 'max_leaves': 72, 'min_child_weight': 3, 'reg_alpha': 0.24039523588312584, 'reg_lambda': 0.9933255840789301, 'min_frequency': 0.6397252902678048}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:36:40,839] Trial 20 finished with value: 2210.8099906404573 and parameters: {'learning_rate': 0.0729567880982453, 'n_estimators': 456, 'max_depth': 8, 'max_leaves': 56, 'min_child_weight': 1, 'reg_alpha': 0.41798188660878577, 'reg_lambda': 0.8108660401354784, 'min_frequency': 0.7992377691982067}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:36:48,459] Trial 21 finished with value: 2203.5544027511423 and parameters: {'learning_rate': 0.058064329631705255, 'n_estimators': 633, 'max_depth': 6, 'max_leaves': 46, 'min_child_weight': 2, 'reg_alpha': 0.2772331383434738, 'reg_lambda': 0.8794166198838947, 'min_frequency': 0.5525031231356182}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:36:55,294] Trial 22 finished with value: 2286.603402478674 and parameters: {'learning_rate': 0.06292242284225265, 'n_estimators': 656, 'max_depth': 5, 'max_leaves': 28, 'min_child_weight': 2, 'reg_alpha': 0.30197962171977333, 'reg_lambda': 0.9978124857443744, 'min_frequency': 0.4748210972657854}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:37:04,903] Trial 23 finished with value: 2244.431470496154 and parameters: {'learning_rate': 0.049253482758517604, 'n_estimators': 783, 'max_depth': 6, 'max_leaves': 44, 'min_child_weight': 2, 'reg_alpha': 0.126717093055723, 'reg_lambda': 0.8967576162725428, 'min_frequency': 0.9091860477422451}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:37:09,199] Trial 24 finished with value: 2303.9436262758845 and parameters: {'learning_rate': 0.0662358009524667, 'n_estimators': 436, 'max_depth': 5, 'max_leaves': 55, 'min_child_weight': 1, 'reg_alpha': 0.2449317233338586, 'reg_lambda': 0.7692031613901148, 'min_frequency': 0.746591497568013}. Best is trial 7 with value: 2167.6634915285986.\n","[I 2023-11-13 12:37:17,601] Trial 25 finished with value: 2128.282494609585 and parameters: {'learning_rate': 0.05685084079013387, 'n_estimators': 602, 'max_depth': 7, 'max_leaves': 68, 'min_child_weight': 3, 'reg_alpha': 0.09613292419469929, 'reg_lambda': 0.8815425582774342, 'min_frequency': 0.3957737371269463}. Best is trial 25 with value: 2128.282494609585.\n","[I 2023-11-13 12:37:22,117] Trial 26 finished with value: 2215.8005634719775 and parameters: {'learning_rate': 0.053147059361664487, 'n_estimators': 294, 'max_depth': 9, 'max_leaves': 84, 'min_child_weight': 4, 'reg_alpha': 0.09181940722933099, 'reg_lambda': 0.8256278321977059, 'min_frequency': 0.6302308757497628}. Best is trial 25 with value: 2128.282494609585.\n","[I 2023-11-13 12:37:27,613] Trial 27 finished with value: 2306.320887728716 and parameters: {'learning_rate': 0.03614904927134494, 'n_estimators': 384, 'max_depth': 7, 'max_leaves': 66, 'min_child_weight': 3, 'reg_alpha': 0.1642358451371784, 'reg_lambda': 0.7387306409769722, 'min_frequency': 0.4193430710631128}. Best is trial 25 with value: 2128.282494609585.\n","[I 2023-11-13 12:37:41,720] Trial 28 finished with value: 2087.9254496706803 and parameters: {'learning_rate': 0.048232679642772225, 'n_estimators': 871, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.05801604630510532, 'reg_lambda': 0.8688602717938263, 'min_frequency': 0.8158495516452512}. Best is trial 28 with value: 2087.9254496706803.\n","[I 2023-11-13 12:37:57,382] Trial 29 finished with value: 2018.5197672034813 and parameters: {'learning_rate': 0.0468266900422592, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 4, 'reg_alpha': 0.0643421560275208, 'reg_lambda': 0.6653124636744349, 'min_frequency': 0.80484650071563}. Best is trial 29 with value: 2018.5197672034813.\n","[I 2023-11-13 12:38:13,912] Trial 30 finished with value: 2113.0851950898095 and parameters: {'learning_rate': 0.03332616030152558, 'n_estimators': 986, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 4, 'reg_alpha': 0.03314237301544933, 'reg_lambda': 0.676491252479811, 'min_frequency': 0.8394718214216204}. Best is trial 29 with value: 2018.5197672034813.\n","[I 2023-11-13 12:38:30,645] Trial 31 finished with value: 2105.1427032245556 and parameters: {'learning_rate': 0.04665074738576534, 'n_estimators': 971, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 4, 'reg_alpha': 0.04995215290720305, 'reg_lambda': 0.6435292477600119, 'min_frequency': 0.8094138667406751}. Best is trial 29 with value: 2018.5197672034813.\n","[I 2023-11-13 12:38:47,016] Trial 32 finished with value: 2112.7834837802857 and parameters: {'learning_rate': 0.03337697101729298, 'n_estimators': 989, 'max_depth': 10, 'max_leaves': 99, 'min_child_weight': 4, 'reg_alpha': 0.04290134787529549, 'reg_lambda': 0.5765800405627541, 'min_frequency': 0.8101152961847616}. Best is trial 29 with value: 2018.5197672034813.\n","[I 2023-11-13 12:39:00,439] Trial 33 finished with value: 2047.1277918160001 and parameters: {'learning_rate': 0.04672811921498857, 'n_estimators': 898, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 4, 'reg_alpha': 0.0528500459958681, 'reg_lambda': 0.5817059112171044, 'min_frequency': 0.8008509916396133}. Best is trial 29 with value: 2018.5197672034813.\n","[I 2023-11-13 12:39:13,879] Trial 34 finished with value: 2093.2882423119445 and parameters: {'learning_rate': 0.04926270830814425, 'n_estimators': 899, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 5, 'reg_alpha': 0.001227207947167984, 'reg_lambda': 0.4922148963490867, 'min_frequency': 0.7941893867527543}. Best is trial 29 with value: 2018.5197672034813.\n","[I 2023-11-13 12:39:27,064] Trial 35 finished with value: 2092.7986376920376 and parameters: {'learning_rate': 0.04916945147224987, 'n_estimators': 871, 'max_depth': 10, 'max_leaves': 90, 'min_child_weight': 5, 'reg_alpha': 0.002544161469660855, 'reg_lambda': 0.4770238394367944, 'min_frequency': 0.78080584310552}. Best is trial 29 with value: 2018.5197672034813.\n","[I 2023-11-13 12:39:39,613] Trial 36 finished with value: 2106.7046987327612 and parameters: {'learning_rate': 0.0429035395712677, 'n_estimators': 875, 'max_depth': 9, 'max_leaves': 81, 'min_child_weight': 5, 'reg_alpha': 0.07480029250155056, 'reg_lambda': 0.3624895839558781, 'min_frequency': 0.9380798720573305}. Best is trial 29 with value: 2018.5197672034813.\n","[I 2023-11-13 12:39:53,026] Trial 37 finished with value: 2071.841647705242 and parameters: {'learning_rate': 0.049689523216122584, 'n_estimators': 913, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 5, 'reg_alpha': 0.154627092780696, 'reg_lambda': 0.5459324233966832, 'min_frequency': 0.690200936284433}. Best is trial 29 with value: 2018.5197672034813.\n"]},{"name":"stdout","output_type":"stream","text":["N칰mero de trials: 38\n","Mejores hiperpar치metros: {'learning_rate': 0.0468266900422592, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 4, 'reg_alpha': 0.0643421560275208, 'reg_lambda': 0.6653124636744349, 'min_frequency': 0.80484650071563}\n","MAE 칩ptimo: 2018.5197672034813\n"]}],"source":["import optuna\n","\n","# Define la funci칩n objetivo para Optuna\n","def objective(trial):\n","    # Definir los rangos de b칰squeda para los hiperpar치metros\n","    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1)\n","    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n","    max_depth = trial.suggest_int('max_depth', 3, 10)\n","    max_leaves = trial.suggest_int('max_leaves', 0, 100)\n","    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n","    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n","    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n","    \n","    min_frequency = trial.suggest_float('min_frequency', 0.0, 1.0)\n","\n","    # Crear un nuevo pipeline con los hiperpar치metros sugeridos por Optuna\n","    xgb_model = XGBRegressor(\n","        learning_rate=learning_rate,\n","        n_estimators=n_estimators,\n","        max_depth=max_depth,\n","        max_leaves=max_leaves,\n","        min_child_weight=min_child_weight,\n","        reg_alpha=reg_alpha,\n","        reg_lambda=reg_lambda,\n","        monotone_constraints=monotone_constraints\n","    )\n","\n","    # Modificar el valor de min_frequency del OneHotEncoder en el ColumnTransformer\n","    for name, transformer, columns in preprocessor.transformers_:\n","        if isinstance(transformer, OneHotEncoder):\n","            transformer.set_params(min_frequency=min_frequency)\n","\n","    pipeline_xgb = Pipeline(steps=[\n","        ('date', date_transformer),\n","        ('preprocessor', preprocessor),\n","        ('regressor', xgb_model)\n","    ])\n","\n","    pipeline_xgb.fit(train_X_reordered, train_Y)\n","\n","    # Calcular MAE en datos de validaci칩n\n","    y_pred = pipeline_xgb.predict(val_X_reordered)\n","    mae = mean_absolute_error(val_Y, y_pred)\n","\n","    return mae\n","\n","# Crear un estudio de Optuna\n","study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=314159))\n","study.optimize(objective, n_trials=100, timeout=300)\n","\n","# Obtener los mejores hiperpar치metros encontrados\n","best_params = study.best_params\n","best_mae = study.best_value\n","num_trials = len(study.trials)\n","\n","print(\"N칰mero de trials:\", num_trials)\n","print(\"Mejores hiperpar치metros:\", best_params)\n","print(\"MAE 칩ptimo:\", best_mae)\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Hiperpar치metros:\n","\n","- learning_rate: es un hiperpar치metro que controla la tasa de aprendizaje del modelo. En este sentido, si la tasa de aprendizaje es muy alta, el modelo aprende r치pidamente, pero hace que este sea inestable, mientras que una tasa de aprendizaje baja hace que el modelo aprenda m치s lentamente, pero de una forma m치s precisa. En este caso se plantea que var칤e entre los decimales 0.001 y 0.1 los cuales son considerados como tasas de aprendizajes relativamente baja y alta respectivamente.\n","- n_estimators: indica la cantidad de 치rboles en el bosque de XGBoost. Una mayor cantidad de 치rboles puede mejorar la capacidad del modelo para capturar las relaciones que son m치s complejas entre las variables, pero al mismo tiempo, al haber m치s estimadores tambi칠n aumenta el tiempo de entrenamiento del modelo. En este caso el valor de n_estimator var칤a entre los enteros 50 y 1000, lo cual es un buen rango para optimizar el modelo.\n","- max_depth: indica la profundidad m치xima que pueden alcanzar los 치rboles generados por el modelo. Una profundidad muy alta puede hacer que el 치rbol se sobreajuste a los datos. Este valor var칤a entre los enteros 3 y 10, lo cual es un buen rango para optimizar el modelo.\n","- max_leaves: indica el n칰mero m치ximo de hojas de cada 치rbol, restringiendo as칤 la complejidad del mismo. Este valor var칤a entre los enteros 0 y 100, lo cual es un buen rango para optimizar el modelo.\n","- min_child_weight: indica el peso m칤nimo (n칰mero de instancias) que debe tener un nodo para generar una nueva divisi칩n del mismo. Un mayor valor de este hiperpar치metro puede restringir el que se produzcan m치s nodos. Este valor var칤a entre los entre los enteros de 1 a 5, lo cual es un buen rango para optimizar el modelo.\n","- reg_alpha: indica el nivel de regularizaci칩n de Lasso a las variables. En este sentido, puede eliminar variables que se vean afectadas por la regularizaci칩n. Este valor var칤a en decimales entre 0 y 1, lo cual es un buen rango para optimizar el modelo.\n","- reg_lambda: indica el nivel de regularizaci칩n de Ridge a las variables. En este sentido, evita que los coeficientes de las variables tomen valores muy altos, pero no elimina variables de la ecuaci칩n. Este valor var칤a en decimales entre 0 y 1, lo cual es un buen rango para optimizar el modelo.\n","- OneHotEncoder (min_frequency): indica el m칤nimo de repeticiones que debe tener una categor칤a para que sea considerada en la codificaci칩n. En este sentido, el valor entregado var칤a entre decimalmente entre 0 y 1. Estos valores entregados al algoritmo son incorrectos, pues no tiene sentido que se entregue valores decimales entre 0 y 1 a min_frequency, cuando esta debe recibir valores enteros mayores a 0."]},{"cell_type":"markdown","metadata":{"cell_id":"5195ccfc37e044ad9453f6eb2754f631","deepnote_cell_type":"markdown"},"source":["## 1.4 Optimizaci칩n de Hiperpar치metros con Optuna y Prunners (1.7)\n","\n","<p align=\"center\">\n","  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n","</p>\n","\n","Despu칠s de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en s칤 mismo. Despu칠s de leer un par de post de personas de dudosa reputaci칩n en la *deepweb*, usted llega a la conclusi칩n que puede cumplir este objetivo mediante la implementaci칩n de **Prunning**.\n","\n","Vuelva a optimizar los mismos hiperpar치metros que la secci칩n pasada, pero esta vez utilizando **Prunning** en la optimizaci칩n. En particular, usted debe:\n","\n","- Responder: 쯈u칠 es prunning? 쮻e qu칠 forma deber칤a impactar en el entrenamiento?\n","- Utilizar `optuna.integration.XGBoostPruningCallback` como m칠todo de **Prunning**\n","- Fijar nuevamente el tiempo de entrenamiento a 5 minutos\n","- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto?\n","- Guardar su modelo en un archivo .pkl\n","\n","Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n","\n","```\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","```\n","\n","De implementar la opci칩n anterior, pueden especificar `show_progress_bar = True` en el m칠todo `optimize` para *m치s sabor*.\n","\n","Hint: Si quieren especificar par치metros del m칠todo .fit() del modelo a trav칠s del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n","\n","Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementaci칩n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"eeaa967cd8f6426d8c54f276c17dce79","deepnote_cell_type":"code"},"outputs":[],"source":["# Inserte su c칩digo ac치"]},{"cell_type":"markdown","metadata":{"cell_id":"8a081778cc704fc6bed05393a5419327","deepnote_cell_type":"markdown"},"source":["## 1.5 Visualizaciones (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n","</p>\n","\n","\n","Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n","\n","A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n","\n","- Gr치fico de historial de optimizaci칩n\n","- Gr치fico de coordenadas paralelas\n","- Gr치fico de importancia de hiperpar치metros\n","\n","Comente sus resultados: 쮻esde qu칠 *trial* se empiezan a observar mejoras notables en sus resultados? 쯈u칠 tendencias puede observar a partir del gr치fico de coordenadas paralelas? 쮺u치les son los hiperpar치metros con mayor importancia para la optimizaci칩n de su modelo?"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"0e706dc9a8d946eda7a9eb1f0463c6d7","deepnote_cell_type":"code"},"outputs":[],"source":["# Inserte su c칩digo ac치"]},{"cell_type":"markdown","metadata":{"cell_id":"ac8a20f445d045a3becf1a518d410a7d","deepnote_cell_type":"markdown"},"source":["## 1.6 S칤ntesis de resultados (0.3)\n","\n","Finalmente, genere una tabla resumen del MAE obtenido en los 5 modelos entrenados (desde Baseline hasta XGBoost con Constraints, Optuna y Prunning) y compare sus resultados. 쯈u칠 modelo obtiene el mejor rendimiento? \n","\n","Por 칰ltimo, cargue el mejor modelo, prediga sobre el conjunto de test y reporte su MAE. 쮼xisten diferencias con respecto a las m칠tricas obtenidas en el conjunto de validaci칩n? 쯇orqu칠 puede ocurrir esto?"]},{"cell_type":"markdown","metadata":{"cell_id":"5c4654d12037494fbd385b4dc6bd1059","deepnote_cell_type":"markdown"},"source":["# Conclusi칩n\n","Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n","</p>"]},{"cell_type":"markdown","metadata":{"cell_id":"5025de06759f4903a26916c80323bf25","deepnote_cell_type":"markdown"},"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"f63d38450a6b464c9bb6385cf11db4d9","deepnote_persisted_session":{"createdAt":"2023-11-09T16:18:30.203Z"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b5c0d2440b3e4995a794ded565213150","deepnote_cell_type":"markdown"},"source":["<h1><center>Laboratorio 9: Optimizaci칩n de modelos 游눮</center></h1>\n","\n","<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos</strong></center>"]},{"cell_type":"markdown","metadata":{"cell_id":"bfb94b9656f145ad83e81b75d218cb70","deepnote_cell_type":"markdown"},"source":["### Cuerpo Docente:\n","\n","- Profesor: Ignacio Meza, Gabriel Iturra\n","- Auxiliar: Sebasti치n Tinoco\n","- Ayudante: Arturo Lazcano, Angelo Mu침oz"]},{"cell_type":"markdown","metadata":{"cell_id":"b1b537fdd27c43909a49d3476ce64d91","deepnote_cell_type":"markdown"},"source":["### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n","\n","- Nombre de alumno 1: Tom치s Aguirre\n","- Nombre de alumno 2: Ignacio Albornoz\n"]},{"cell_type":"markdown","metadata":{"cell_id":"b7dbdd30ab544cb8a8afe00648a586ae","deepnote_cell_type":"markdown"},"source":["## Temas a tratar\n","\n","- Predicci칩n de demanda usando `xgboost`\n","- B칰squeda del modelo 칩ptimo de clasificaci칩n usando `optuna`\n","- Uso de pipelines.\n","\n","## Reglas:\n","\n","- **Grupos de 2 personas**\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n","- Prohibidas las copias. \n","- Pueden usar cualquer material del curso que estimen conveniente.\n","\n","### Objetivos principales del laboratorio\n","\n","- Optimizar modelos usando `optuna`\n","- Recurrir a t칠cnicas de *prunning*\n","- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n","- Fijar un pipeline con un modelo base que luego se ir치 optimizando.\n","\n","El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."]},{"cell_type":"markdown","metadata":{"cell_id":"f38c8342f5164aa992a97488dd5590bf","deepnote_cell_type":"markdown"},"source":["### **Link de repositorio de GitHub:** `https://github.com/tomasaguirre-ignacioalbornoz/MDS7202`"]},{"cell_type":"markdown","metadata":{"cell_id":"f1c73babb7f74af588a4fa6ae14829e0","deepnote_cell_type":"markdown"},"source":["# Importamos librerias 칰tiles"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"51afe4d2df42442b9e5402ffece60ead","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4957,"execution_start":1699544354044,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: joblib in /home/ignacio/miniconda3/envs/.proyecto1mds/lib/python3.11/site-packages (1.3.2)\n"]}],"source":["!pip install -qq xgboost optuna\n","!pip install joblib"]},{"cell_type":"markdown","metadata":{"cell_id":"44d227389a734ac59189c5e0005bc68a","deepnote_cell_type":"markdown"},"source":["# 1. El emprendimiento de Fiu\n","\n","Tras liderar de manera exitosa la implementaci칩n de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corp칩reo **Fiu** se anima y decide levantar su propio negocio de consultor칤a en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Como usted tuvo un rendimiento sobresaliente en el proyecto de caracterizaci칩n de datos, Fiu lo contrata como *data scientist* de su emprendimiento.\n","\n","Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n","\n","Para comenzar, cargue el dataset se침alado y visualice a trav칠s de un `.head` los atributos que posee el dataset.\n","\n","<i><p align=\"center\">Fiu siendo felicitado por su excelente desempe침o en el proyecto de caracterizaci칩n de datos</p></i>\n","<p align=\"center\">\n","  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n","</p>"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"2f9c82d204b14515ad27ae07e0b77702","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":92,"execution_start":1699544359006,"source_hash":null},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>date</th>\n","      <th>city</th>\n","      <th>lat</th>\n","      <th>long</th>\n","      <th>pop</th>\n","      <th>shop</th>\n","      <th>brand</th>\n","      <th>container</th>\n","      <th>capacity</th>\n","      <th>price</th>\n","      <th>quantity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6480</td>\n","      <td>2018-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>664046</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>plastic</td>\n","      <td>1.5lt</td>\n","      <td>3.10</td>\n","      <td>7056</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6481</td>\n","      <td>2018-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>664046</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>can</td>\n","      <td>330ml</td>\n","      <td>0.85</td>\n","      <td>12490</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6482</td>\n","      <td>2018-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>664046</td>\n","      <td>shop_1</td>\n","      <td>adult-cola</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>0.83</td>\n","      <td>26640</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6483</td>\n","      <td>2018-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>664046</td>\n","      <td>shop_1</td>\n","      <td>orange-power</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>0.54</td>\n","      <td>41892</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6484</td>\n","      <td>2018-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>664046</td>\n","      <td>shop_1</td>\n","      <td>orange-power</td>\n","      <td>plastic</td>\n","      <td>1.5lt</td>\n","      <td>0.83</td>\n","      <td>22923</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     id       date    city       lat      long     pop    shop         brand  \\\n","0  6480 2018-01-31  Athens  37.97945  23.71622  664046  shop_1   kinder-cola   \n","1  6481 2018-01-31  Athens  37.97945  23.71622  664046  shop_1   kinder-cola   \n","2  6482 2018-01-31  Athens  37.97945  23.71622  664046  shop_1    adult-cola   \n","3  6483 2018-01-31  Athens  37.97945  23.71622  664046  shop_1  orange-power   \n","4  6484 2018-01-31  Athens  37.97945  23.71622  664046  shop_1  orange-power   \n","\n","  container capacity  price  quantity  \n","0   plastic    1.5lt   3.10      7056  \n","1       can    330ml   0.85     12490  \n","2     glass    500ml   0.83     26640  \n","3     glass    500ml   0.54     41892  \n","4   plastic    1.5lt   0.83     22923  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","\n","df = pd.read_csv('sales.csv')\n","df['date'] = pd.to_datetime(df['date'], format='%d/%m/%y')\n","\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"cell_id":"b50db6f2cb804932ae3f9e5748a6ea61","deepnote_cell_type":"markdown"},"source":["## 1.1 Generando un Baseline (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n","</p>\n","\n","Antes de entrenar un algoritmo, usted recuerda los apuntes de su mag칤ster en ciencia de datos y recuerda que debe seguir una serie de *buenas pr치cticas* para entrenar correcta y debidamente su modelo. Despu칠s de un par de vueltas, llega a las siguientes tareas:\n","\n","1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad.\n","2. Implemente un `FunctionTransformer` para extraer el d칤a, mes y a침o de la variable `date`. Guarde estas variables en el formato categorical de pandas.\n","3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos num칠ricos y categ칩ricos. Use `OneHotEncoder` para las variables categ칩ricas.\n","4. Guarde los pasos anteriores en un `Pipeline`, dejando como 칰ltimo paso el regresor `DummyRegressor` para generar predicciones en base a promedios.\n","5. Entrene el pipeline anterior y reporte la m칠trica `mean_absolute_error` sobre los datos de validaci칩n. 쮺칩mo se interpreta esta m칠trica para el contexto del negocio?\n","6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los par치metros por default**. 쮺칩mo cambia el MAE al implementar este algoritmo? 쮼s mejor o peor que el `DummyRegressor`?\n","7. Guarde ambos modelos en un archivo .pkl (uno cada uno)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   price    id    city       lat      long     pop    shop         brand  \\\n","0   3.10  6480  Athens  37.97945  23.71622  664046  shop_1   kinder-cola   \n","1   0.85  6481  Athens  37.97945  23.71622  664046  shop_1   kinder-cola   \n","2   0.83  6482  Athens  37.97945  23.71622  664046  shop_1    adult-cola   \n","3   0.54  6483  Athens  37.97945  23.71622  664046  shop_1  orange-power   \n","4   0.83  6484  Athens  37.97945  23.71622  664046  shop_1  orange-power   \n","\n","  container capacity  quantity day month  year  \n","0   plastic    1.5lt      7056  31     1  2018  \n","1       can    330ml     12490  31     1  2018  \n","2     glass    500ml     26640  31     1  2018  \n","3     glass    500ml     41892  31     1  2018  \n","4   plastic    1.5lt     22923  31     1  2018  \n","numeric_features\n","Index(['id', 'lat', 'long', 'pop', 'price'], dtype='object')\n","categorical_features\n","['day', 'month', 'year', 'city', 'shop', 'brand', 'container', 'capacity', 'day', 'month', 'year']\n","Index(['id', 'date', 'city', 'lat', 'long', 'pop', 'shop', 'brand',\n","       'container', 'capacity', 'price'],\n","      dtype='object')\n","MAE con DummyRegressor: 12026.96788653733\n","MAE con XGBRegressor: 4208.507968478732\n"]},{"data":{"text/plain":["['model_xgb.pkl']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Importar librer칤as necesarias\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.dummy import DummyRegressor\n","from sklearn.metrics import mean_absolute_error\n","from xgboost import XGBRegressor\n","import joblib\n","\n","\n","# Separar en conjuntos de train, validation y test\n","train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n","val_df, test_df = train_test_split(temp_df, test_size=(1/3), random_state=42)\n","\n","# Crear un FunctionTransformer para extraer d칤a, mes y a침o\n","def extract_date_parts(df):\n","    df['day'] = df['date'].dt.day.astype('category')\n","    df['month'] = df['date'].dt.month.astype('category')\n","    df['year'] = df['date'].dt.year.astype('category')\n","    df = df.drop(columns=['date'])\n","    # Crear una lista con 'price' como el primer elemento seguido por el resto de las columnas\n","    ordered_columns = ['price'] + [col for col in df.columns if col != 'price']\n","    return df[ordered_columns]\n","\n","print(extract_date_parts(df).head())\n","\n","date_transformer = FunctionTransformer(extract_date_parts, validate=False)\n","\n","# Crear un ColumnTransformer para procesar los datos\n","#numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n","\n","numeric_features = df.select_dtypes(include=['int64', 'float64']).drop('quantity', axis=1).columns\n","\n","\n","# Lista inicial de caracter칤sticas categ칩ricas\n","categorical_features = ['day', 'month', 'year']\n","\n","# A침adir columnas del DataFrame que no son de tipo int64 o float64\n","categorical_features.extend(df.select_dtypes(exclude=['int64', 'float64']).columns)\n","\n","# Excluir la columna 'date'\n","categorical_features.remove('date')\n","\n","print(\"numeric_features\")\n","print(numeric_features)\n","print(\"categorical_features\")\n","print(categorical_features)\n","\n","# Creando un dataframe que solo contiene la columna 'quantity'\n","train_Y = train_df[['quantity']]\n","\n","# Creando otro dataframe que contiene todas las columnas excepto 'quantity'\n","train_X = train_df.drop(columns=['quantity'])\n","\n","print(train_X.columns)\n","\n","# Creando un dataframe que solo contiene la columna 'quantity'\n","test_Y = test_df[['quantity']]\n","\n","# Creando otro dataframe que contiene todas las columnas excepto 'quantity'\n","test_X = test_df.drop(columns=['quantity'])\n","\n","# Creando un dataframe que solo contiene la columna 'quantity'\n","val_Y= val_df[['quantity']]\n","\n","# Creando otro dataframe que contiene todas las columnas excepto 'quantity'\n","val_X = val_df.drop(columns=['quantity'])\n","\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', 'passthrough', numeric_features),\n","        ('cat', OneHotEncoder(sparse_output=False), categorical_features)\n","    ])\n","\n","# Crear y entrenar el pipeline con DummyRegressor\n","pipeline_dummy = Pipeline(steps=[\n","    ('date', date_transformer),\n","    ('preprocessor', preprocessor),\n","    ('regressor', DummyRegressor(strategy='mean'))\n","])\n","\n","\n","#print(\"debug1\")\n","pipeline_dummy.fit(train_X, train_Y) \n","\n","# Evaluar el modelo\n","y_pred = pipeline_dummy.predict(val_X)\n","\n","mae_dummy = mean_absolute_error(val_Y, y_pred)\n","print(f'MAE con DummyRegressor: {mae_dummy}')\n","\n","\n","# Reemplazar DummyRegressor con XGBRegressor y entrenar nuevamente\n","pipeline_xgb = Pipeline(steps=[\n","    ('date', date_transformer),\n","    ('preprocessor', preprocessor),\n","    ('regressor', XGBRegressor())\n","])\n","\n","pipeline_xgb.fit(train_X, train_Y) \n","\n","# Evaluar el nuevo modelo\n","y_pred_xgb = pipeline_xgb.predict(val_X)\n","mae_xgb = mean_absolute_error(val_Y, y_pred_xgb)\n","print(f'MAE con XGBRegressor: {mae_xgb}')\n","\n","# Guardar los modelos\n","joblib.dump(pipeline_dummy, 'model_dummy.pkl')\n","joblib.dump(pipeline_xgb, 'model_xgb.pkl')\n"]},{"cell_type":"markdown","metadata":{"cell_id":"7e17e46063774ec28226fe300d42ffe0","deepnote_cell_type":"markdown"},"source":["## 1.2 Forzando relaciones entre par치metros con XGBoost (1.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n","</p>\n","\n","Un colega aficionado a la econom칤a le *sopla* que la demanda guarda una relaci칩n inversa con el precio del producto. Motivado para impresionar al querido corp칩reo, se propone hacer uso de esta informaci칩n para mejorar su modelo.\n","\n","Vuelva a entrenar el `Pipeline`, pero esta vez forzando una relaci칩n mon칩tona negativa entre el precio y la cantidad. Luego, vuelva a reportar el `MAE` sobre el conjunto de validaci칩n. 쮺칩mo cambia el error al incluir esta relaci칩n? 쯊en칤a raz칩n su amigo?\n","\n","Nuevamente, guarde su modelo en un archivo .pkl\n","\n","Nota: Para realizar esta parte, debe apoyarse en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentaci칩n</a>.\n","\n","Hint: Para implementar el constraint, se le sugiere hacerlo especificando el nombre de la variable. De ser as칤, probablemente le sea 칰til **mantener el formato de pandas** antes del step de entrenamiento."]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"f469f3b572be434191d2d5c3f11b20d2","deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE con XGBRegressor y constraint mon칩tono: 4172.883096200449\n"]},{"data":{"text/plain":["['model_xgb_monotone.pkl']"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.base import BaseEstimator, TransformerMixin\n","\n","# Definir los constraints de monoton칤a\n","# Asumiendo que 'price' es la primera columna despu칠s del preprocesamiento\n","# -1 indica una relaci칩n mon칩tona negativa\n","monotone_constraints = (-1,)\n","\n","'''\n","class DataInspector:\n","    def fit(self, X, y=None):\n","        # Check if X is a DataFrame or a NumPy array\n","        if isinstance(X, pd.DataFrame):\n","            # Print the first few rows of the DataFrame\n","            print(X.head())\n","        elif isinstance(X, np.ndarray):\n","            # Print the first few rows of the NumPy array\n","            print(X[:5])\n","        return self\n","\n","    def transform(self, X):\n","        return X\n","\n","'''\n","# Incluir el inspector de datos en el pipeline antes del regresor\n","pipeline_xgb_monotone = Pipeline(steps=[\n","    ('date', date_transformer),\n","    ('preprocessor', preprocessor),\n","    # ('inspector', DataInspector()),  # Paso de inspecci칩n agregado aqu칤\n","    ('regressor', XGBRegressor(monotone_constraints=monotone_constraints))\n","])\n","\n","\n","pipeline_xgb_monotone.fit(train_X, train_Y)\n","\n","# Evaluar el modelo\n","y_pred_xgb_monotone = pipeline_xgb_monotone.predict(val_X)\n","mae_xgb_monotone = mean_absolute_error(val_Y, y_pred_xgb_monotone)\n","print(f'MAE con XGBRegressor y constraint mon칩tono: {mae_xgb_monotone}')\n","\n","# Guardar el modelo\n","joblib.dump(pipeline_xgb_monotone, 'model_xgb_monotone.pkl')\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"e59ef80ed20b4de8921f24da74e87374","deepnote_cell_type":"markdown"},"source":["## 1.3 Optimizaci칩n de Hiperpar치metros con Optuna (2.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n","</p>\n","\n","Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun m치s* su modelo. En particular, le comenta de la optimizaci칩n de hiperpar치metros con metodolog칤as bayesianas a trav칠s del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n","\n","A partir de la mejor configuraci칩n obtenida en la secci칩n anterior, utilice `optuna` para optimizar sus hiperpar치metros. En particular, se le pide:\n","\n","- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n","- Utilice `TPESampler` como m칠todo de muestreo\n","- De `XGBRegressor`, optimice los siguientes hiperpar치metros:\n","    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n","    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n","    - `max_depth` buscando valores enteros en el rango (3, 10)\n","    - `max_leaves` buscando valores enteros en el rango (0, 100)\n","    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n","    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n","    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n","- De `OneHotEncoder`, optimice el hiperpar치metro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n","- Explique cada hiperpar치metro y su rol en el modelo. 쮿acen sentido los rangos de optimizaci칩n indicados?\n","- Fije el tiempo de entrenamiento a 5 minutos\n","- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto?\n","- Guardar su modelo en un archivo .pkl"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"de5914621cc64cb0b1bacb9ff565a97e","deepnote_cell_type":"code"},"outputs":[],"source":["# Inserte su c칩digo ac치"]},{"cell_type":"markdown","metadata":{"cell_id":"5195ccfc37e044ad9453f6eb2754f631","deepnote_cell_type":"markdown"},"source":["## 1.4 Optimizaci칩n de Hiperpar치metros con Optuna y Prunners (1.7)\n","\n","<p align=\"center\">\n","  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n","</p>\n","\n","Despu칠s de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en s칤 mismo. Despu칠s de leer un par de post de personas de dudosa reputaci칩n en la *deepweb*, usted llega a la conclusi칩n que puede cumplir este objetivo mediante la implementaci칩n de **Prunning**.\n","\n","Vuelva a optimizar los mismos hiperpar치metros que la secci칩n pasada, pero esta vez utilizando **Prunning** en la optimizaci칩n. En particular, usted debe:\n","\n","- Responder: 쯈u칠 es prunning? 쮻e qu칠 forma deber칤a impactar en el entrenamiento?\n","- Utilizar `optuna.integration.XGBoostPruningCallback` como m칠todo de **Prunning**\n","- Fijar nuevamente el tiempo de entrenamiento a 5 minutos\n","- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto?\n","- Guardar su modelo en un archivo .pkl\n","\n","Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n","\n","```\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","```\n","\n","De implementar la opci칩n anterior, pueden especificar `show_progress_bar = True` en el m칠todo `optimize` para *m치s sabor*.\n","\n","Hint: Si quieren especificar par치metros del m칠todo .fit() del modelo a trav칠s del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n","\n","Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementaci칩n"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"eeaa967cd8f6426d8c54f276c17dce79","deepnote_cell_type":"code"},"outputs":[],"source":["# Inserte su c칩digo ac치"]},{"cell_type":"markdown","metadata":{"cell_id":"8a081778cc704fc6bed05393a5419327","deepnote_cell_type":"markdown"},"source":["## 1.5 Visualizaciones (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n","</p>\n","\n","\n","Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n","\n","A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n","\n","- Gr치fico de historial de optimizaci칩n\n","- Gr치fico de coordenadas paralelas\n","- Gr치fico de importancia de hiperpar치metros\n","\n","Comente sus resultados: 쮻esde qu칠 *trial* se empiezan a observar mejoras notables en sus resultados? 쯈u칠 tendencias puede observar a partir del gr치fico de coordenadas paralelas? 쮺u치les son los hiperpar치metros con mayor importancia para la optimizaci칩n de su modelo?"]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"0e706dc9a8d946eda7a9eb1f0463c6d7","deepnote_cell_type":"code"},"outputs":[],"source":["# Inserte su c칩digo ac치"]},{"cell_type":"markdown","metadata":{"cell_id":"ac8a20f445d045a3becf1a518d410a7d","deepnote_cell_type":"markdown"},"source":["## 1.6 S칤ntesis de resultados (0.3)\n","\n","Finalmente, genere una tabla resumen del MAE obtenido en los 5 modelos entrenados (desde Baseline hasta XGBoost con Constraints, Optuna y Prunning) y compare sus resultados. 쯈u칠 modelo obtiene el mejor rendimiento? \n","\n","Por 칰ltimo, cargue el mejor modelo, prediga sobre el conjunto de test y reporte su MAE. 쮼xisten diferencias con respecto a las m칠tricas obtenidas en el conjunto de validaci칩n? 쯇orqu칠 puede ocurrir esto?"]},{"cell_type":"markdown","metadata":{"cell_id":"5c4654d12037494fbd385b4dc6bd1059","deepnote_cell_type":"markdown"},"source":["# Conclusi칩n\n","Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n","</p>"]},{"cell_type":"markdown","metadata":{"cell_id":"5025de06759f4903a26916c80323bf25","deepnote_cell_type":"markdown"},"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"f63d38450a6b464c9bb6385cf11db4d9","deepnote_persisted_session":{"createdAt":"2023-11-09T16:18:30.203Z"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
