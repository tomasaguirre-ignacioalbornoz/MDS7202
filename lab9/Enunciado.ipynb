{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b5c0d2440b3e4995a794ded565213150","deepnote_cell_type":"markdown"},"source":["<h1><center>Laboratorio 9: Optimización de modelos 💯</center></h1>\n","\n","<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"]},{"cell_type":"markdown","metadata":{"cell_id":"bfb94b9656f145ad83e81b75d218cb70","deepnote_cell_type":"markdown"},"source":["### Cuerpo Docente:\n","\n","- Profesor: Ignacio Meza, Gabriel Iturra\n","- Auxiliar: Sebastián Tinoco\n","- Ayudante: Arturo Lazcano, Angelo Muñoz"]},{"cell_type":"markdown","metadata":{"cell_id":"b1b537fdd27c43909a49d3476ce64d91","deepnote_cell_type":"markdown"},"source":["### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n","\n","- Nombre de alumno 1: Tomás Aguirre\n","- Nombre de alumno 2: Ignacio Albornoz\n"]},{"cell_type":"markdown","metadata":{"cell_id":"b7dbdd30ab544cb8a8afe00648a586ae","deepnote_cell_type":"markdown"},"source":["## Temas a tratar\n","\n","- Predicción de demanda usando `xgboost`\n","- Búsqueda del modelo óptimo de clasificación usando `optuna`\n","- Uso de pipelines.\n","\n","## Reglas:\n","\n","- **Grupos de 2 personas**\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n","- Prohibidas las copias. \n","- Pueden usar cualquer material del curso que estimen conveniente.\n","\n","### Objetivos principales del laboratorio\n","\n","- Optimizar modelos usando `optuna`\n","- Recurrir a técnicas de *prunning*\n","- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n","- Fijar un pipeline con un modelo base que luego se irá optimizando.\n","\n","El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."]},{"cell_type":"markdown","metadata":{"cell_id":"f38c8342f5164aa992a97488dd5590bf","deepnote_cell_type":"markdown"},"source":["### **Link de repositorio de GitHub:** `https://github.com/tomasaguirre-ignacioalbornoz/MDS7202`"]},{"cell_type":"markdown","metadata":{"cell_id":"f1c73babb7f74af588a4fa6ae14829e0","deepnote_cell_type":"markdown"},"source":["# Importamos librerias útiles"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"51afe4d2df42442b9e5402ffece60ead","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4957,"execution_start":1699544354044,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: joblib in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (1.3.2)\n","Requirement already satisfied: pandas in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (2.1.3)\n","Requirement already satisfied: numpy<2,>=1.23.2 in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (from pandas) (1.26.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (from pandas) (2023.3)\n","Requirement already satisfied: six>=1.5 in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: scikit-learn in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (1.3.2)\n","Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (from scikit-learn) (1.26.2)\n","Requirement already satisfied: scipy>=1.5.0 in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (from scikit-learn) (1.11.3)\n","Requirement already satisfied: joblib>=1.1.1 in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n"]}],"source":["!pip install -qq xgboost optuna\n","!pip install joblib\n","!pip install pandas\n","!pip install scikit-learn"]},{"cell_type":"markdown","metadata":{"cell_id":"44d227389a734ac59189c5e0005bc68a","deepnote_cell_type":"markdown"},"source":["# 1. El emprendimiento de Fiu\n","\n","Tras liderar de manera exitosa la implementación de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corpóreo **Fiu** se anima y decide levantar su propio negocio de consultoría en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Como usted tuvo un rendimiento sobresaliente en el proyecto de caracterización de datos, Fiu lo contrata como *data scientist* de su emprendimiento.\n","\n","Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n","\n","Para comenzar, cargue el dataset señalado y visualice a través de un `.head` los atributos que posee el dataset.\n","\n","<i><p align=\"center\">Fiu siendo felicitado por su excelente desempeño en el proyecto de caracterización de datos</p></i>\n","<p align=\"center\">\n","  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n","</p>"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"2f9c82d204b14515ad27ae07e0b77702","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":92,"execution_start":1699544359006,"source_hash":null},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>date</th>\n","      <th>city</th>\n","      <th>lat</th>\n","      <th>long</th>\n","      <th>pop</th>\n","      <th>shop</th>\n","      <th>brand</th>\n","      <th>container</th>\n","      <th>capacity</th>\n","      <th>price</th>\n","      <th>quantity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>0.96</td>\n","      <td>13280</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>plastic</td>\n","      <td>1.5lt</td>\n","      <td>2.86</td>\n","      <td>6727</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>can</td>\n","      <td>330ml</td>\n","      <td>0.87</td>\n","      <td>9848</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>adult-cola</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>1.00</td>\n","      <td>20050</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>adult-cola</td>\n","      <td>can</td>\n","      <td>330ml</td>\n","      <td>0.39</td>\n","      <td>25696</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id       date    city       lat      long     pop    shop        brand  \\\n","0   0 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","1   1 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","2   2 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","3   3 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n","4   4 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n","\n","  container capacity  price  quantity  \n","0     glass    500ml   0.96     13280  \n","1   plastic    1.5lt   2.86      6727  \n","2       can    330ml   0.87      9848  \n","3     glass    500ml   1.00     20050  \n","4       can    330ml   0.39     25696  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","\n","df = pd.read_csv('sales.csv')\n","df['date'] = pd.to_datetime(df['date'], format='%d/%m/%y')\n","\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"cell_id":"b50db6f2cb804932ae3f9e5748a6ea61","deepnote_cell_type":"markdown"},"source":["## 1.1 Generando un Baseline (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n","</p>\n","\n","Antes de entrenar un algoritmo, usted recuerda los apuntes de su magíster en ciencia de datos y recuerda que debe seguir una serie de *buenas prácticas* para entrenar correcta y debidamente su modelo. Después de un par de vueltas, llega a las siguientes tareas:\n","\n","1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad.\n","2. Implemente un `FunctionTransformer` para extraer el día, mes y año de la variable `date`. Guarde estas variables en el formato categorical de pandas.\n","3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos numéricos y categóricos. Use `OneHotEncoder` para las variables categóricas.\n","4. Guarde los pasos anteriores en un `Pipeline`, dejando como último paso el regresor `DummyRegressor` para generar predicciones en base a promedios.\n","5. Entrene el pipeline anterior y reporte la métrica `mean_absolute_error` sobre los datos de validación. ¿Cómo se interpreta esta métrica para el contexto del negocio?\n","6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los parámetros por default**. ¿Cómo cambia el MAE al implementar este algoritmo? ¿Es mejor o peor que el `DummyRegressor`?\n","7. Guarde ambos modelos en un archivo .pkl (uno cada uno)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE con DummyRegressor: 13298.497767341096\n","Features after preprocessing: ['price', 'id', 'lat', 'long', 'pop', 'day_28', 'day_29', 'day_30', 'day_31', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12', 'year_2012', 'year_2013', 'year_2014', 'year_2015', 'year_2016', 'year_2017', 'year_2018', 'city_Athens', 'city_Irakleion', 'city_Larisa', 'city_Patra', 'city_Thessaloniki', 'shop_shop_1', 'shop_shop_2', 'shop_shop_3', 'shop_shop_4', 'shop_shop_5', 'shop_shop_6', 'brand_adult-cola', 'brand_gazoza', 'brand_kinder-cola', 'brand_lemon-boost', 'brand_orange-power', 'container_can', 'container_glass', 'container_plastic', 'capacity_1.5lt', 'capacity_330ml', 'capacity_500ml']\n","MAE con XGBRegressor: 2424.366823499591\n"]},{"data":{"text/plain":["['model_xgb.pkl']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Importar librerías necesarias\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, MinMaxScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.dummy import DummyRegressor\n","from sklearn.metrics import mean_absolute_error\n","from xgboost import XGBRegressor\n","import joblib\n","\n","\n","ordered_columns = ['price'] + [col for col in df.columns if col != 'price']\n","df = df[ordered_columns]\n","\n","# Crear un FunctionTransformer para extraer día, mes y año\n","def extract_date_parts(df):\n","    df['day'] = df['date'].dt.day.astype('category')\n","    df['month'] = df['date'].dt.month.astype('category')\n","    df['year'] = df['date'].dt.year.astype('category')\n","    df = df.drop(columns=['date'])\n","    # Crear una lista con 'price' como el primer elemento seguido por el resto de las columnas\n","    #ordered_columns = ['price'] + [col for col in df.columns if col != 'price']\n","    #df = df[ordered_columns]\n","    return df\n","\n","\n","\n","\n","\n","\n","def get_feature_names(column_transformer):\n","    \"\"\"Get feature names from a ColumnTransformer.\"\"\"\n","    output_features = []\n","\n","    for name, pipe, features in column_transformer.transformers_:\n","        # Process each transformer\n","        if name != 'remainder':\n","            if hasattr(pipe, 'get_feature_names_out'):\n","                # If the transformer has a get_feature_names_out method, use it\n","                feature_names = pipe.get_feature_names_out(features)\n","                output_features.extend(feature_names)\n","            else:\n","                # Otherwise, just append the feature names as is\n","                output_features.extend(features)\n","        else:\n","            # If the remainder transformer is used, handle accordingly\n","            remainder_features = [f for f in features if f not in output_features]\n","            output_features.extend(remainder_features)\n","\n","    return output_features\n","\n","\n","\n","# Separar en conjuntos de train, validation y test\n","train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n","val_df, test_df = train_test_split(temp_df, test_size=(1/3), random_state=42)\n","\n","\n","\n","#print(extract_date_parts(df).head())\n","\n","date_transformer = FunctionTransformer(extract_date_parts, validate=False)\n","\n","# Crear un ColumnTransformer para procesar los datos\n","#numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n","\n","numeric_features = df.select_dtypes(include=['int64', 'float64']).drop('quantity', axis=1).columns\n","\n","\n","# Lista inicial de características categóricas\n","categorical_features = ['day', 'month', 'year']\n","\n","# Añadir columnas del DataFrame que no son de tipo int64 o float64\n","categorical_features.extend(df.select_dtypes(exclude=['int64', 'float64']).columns)\n","\n","# Excluir la columna 'date'\n","categorical_features.remove('date')\n","\n","\n","'''\n","print(\"numeric_features\")\n","print(numeric_features)\n","print(\"categorical_features\")\n","print(categorical_features)\n","'''\n","# Creando un dataframe que solo contiene la columna 'quantity'\n","train_Y = train_df[['quantity']]\n","\n","# Creando otro dataframe que contiene todas las columnas excepto 'quantity'\n","train_X = train_df.drop(columns=['quantity'])\n","\n","#print(train_X.columns)\n","\n","# Creando un dataframe que solo contiene la columna 'quantity'\n","test_Y = test_df[['quantity']]\n","\n","# Creando otro dataframe que contiene todas las columnas excepto 'quantity'\n","test_X = test_df.drop(columns=['quantity'])\n","\n","# Creando un dataframe que solo contiene la columna 'quantity'\n","val_Y= val_df[['quantity']]\n","\n","# Creando otro dataframe que contiene todas las columnas excepto 'quantity'\n","val_X = val_df.drop(columns=['quantity'])\n","\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', MinMaxScaler(), numeric_features),\n","        ('cat', OneHotEncoder(sparse_output=False), categorical_features)\n","    ])\n","\n","'''\n","# Fit and transform the data\n","df_eda = preprocessor.fit_transform(df)\n","\n","# Extract feature names for categorical features transformed by OneHotEncoder\n","# If 'cat' is the name given to the OneHotEncoder step in your ColumnTransformer\n","cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out()\n","\n","print(cat_feature_names)\n","\n","# Concatenate all feature names (numeric + categorical)\n","all_feature_names = numeric_features + list(cat_feature_names)\n","\n","# Create a DataFrame with the new feature names\n","df_eda = pd.DataFrame(df_eda, columns=all_feature_names)\n","\n","# Now you can use the corr() method\n","print(df_eda.corr())\n","'''\n","\n","# Crear y entrenar el pipeline con DummyRegressor\n","pipeline_dummy = Pipeline(steps=[\n","    ('date', date_transformer),\n","    ('preprocessor', preprocessor),\n","    ('regressor', DummyRegressor(strategy='mean'))\n","])\n","\n","\n","#print(\"debug1\")\n","pipeline_dummy.fit(train_X, train_Y) \n","\n","# Evaluar el modelo\n","y_pred = pipeline_dummy.predict(val_X)\n","\n","mae_dummy = mean_absolute_error(val_Y, y_pred)\n","print(f'MAE con DummyRegressor: {mae_dummy}')\n","\n","\n","# After fitting your pipeline, call this function\n","feature_names_after_preprocessing = get_feature_names(pipeline_dummy.named_steps['preprocessor'])\n","print(\"Features after preprocessing:\", feature_names_after_preprocessing)\n","\n","\n","# Reemplazar DummyRegressor con XGBRegressor y entrenar nuevamente\n","pipeline_xgb = Pipeline(steps=[\n","    ('date', date_transformer),\n","    ('preprocessor', preprocessor),\n","    ('regressor', XGBRegressor())\n","])\n","\n","pipeline_xgb.fit(train_X, train_Y) \n","\n","# Evaluar el nuevo modelo\n","y_pred_xgb = pipeline_xgb.predict(val_X)\n","mae_xgb = mean_absolute_error(val_Y, y_pred_xgb)\n","print(f'MAE con XGBRegressor: {mae_xgb}')\n","\n","# Guardar los modelos\n","joblib.dump(pipeline_dummy, 'model_dummy.pkl')\n","joblib.dump(pipeline_xgb, 'model_xgb.pkl')\n"]},{"cell_type":"markdown","metadata":{"cell_id":"7e17e46063774ec28226fe300d42ffe0","deepnote_cell_type":"markdown"},"source":["## 1.2 Forzando relaciones entre parámetros con XGBoost (1.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n","</p>\n","\n","Un colega aficionado a la economía le *sopla* que la demanda guarda una relación inversa con el precio del producto. Motivado para impresionar al querido corpóreo, se propone hacer uso de esta información para mejorar su modelo.\n","\n","Vuelva a entrenar el `Pipeline`, pero esta vez forzando una relación monótona negativa entre el precio y la cantidad. Luego, vuelva a reportar el `MAE` sobre el conjunto de validación. ¿Cómo cambia el error al incluir esta relación? ¿Tenía razón su amigo?\n","\n","Nuevamente, guarde su modelo en un archivo .pkl\n","\n","Nota: Para realizar esta parte, debe apoyarse en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentación</a>.\n","\n","Hint: Para implementar el constraint, se le sugiere hacerlo especificando el nombre de la variable. De ser así, probablemente le sea útil **mantener el formato de pandas** antes del step de entrenamiento."]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"f469f3b572be434191d2d5c3f11b20d2","deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE con XGBRegressor y constraint monótono: 2500.521823322749\n"]},{"data":{"text/plain":["['model_xgb_monotone.pkl']"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Definir los constraints de monotonía\n","# Asumiendo que 'price' es la primera columna después del preprocesamiento\n","# -1 indica una relación monótona negativa\n","monotone_constraints = (-1,)\n","\n","# Incluir el inspector de datos en el pipeline antes del regresor\n","pipeline_xgb_monotone = Pipeline(steps=[\n","    ('date', date_transformer),\n","    ('preprocessor', preprocessor),\n","    ('regressor', XGBRegressor(monotone_constraints=monotone_constraints))\n","])\n","\n","pipeline_xgb_monotone.fit(train_X, train_Y)\n","\n","# Evaluar el modelo\n","y_pred_xgb_monotone = pipeline_xgb_monotone.predict(val_X)\n","mae_xgb_monotone = mean_absolute_error(val_Y, y_pred_xgb_monotone)\n","print(f'MAE con XGBRegressor y constraint monótono: {mae_xgb_monotone}')\n","\n","# Guardar el modelo\n","joblib.dump(pipeline_xgb_monotone, 'model_xgb_monotone.pkl')\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"e59ef80ed20b4de8921f24da74e87374","deepnote_cell_type":"markdown"},"source":["## 1.3 Optimización de Hiperparámetros con Optuna (2.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n","</p>\n","\n","Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun más* su modelo. En particular, le comenta de la optimización de hiperparámetros con metodologías bayesianas a través del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n","\n","A partir de la mejor configuración obtenida en la sección anterior, utilice `optuna` para optimizar sus hiperparámetros. En particular, se le pide:\n","\n","- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n","- Utilice `TPESampler` como método de muestreo\n","- De `XGBRegressor`, optimice los siguientes hiperparámetros:\n","    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n","    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n","    - `max_depth` buscando valores enteros en el rango (3, 10)\n","    - `max_leaves` buscando valores enteros en el rango (0, 100)\n","    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n","    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n","    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n","- De `OneHotEncoder`, optimice el hiperparámetro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n","- Explique cada hiperparámetro y su rol en el modelo. ¿Hacen sentido los rangos de optimización indicados?\n","- Fije el tiempo de entrenamiento a 5 minutos\n","- Reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto?\n","- Guardar su modelo en un archivo .pkl"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"de5914621cc64cb0b1bacb9ff565a97e","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ignacio/miniconda3/envs/lab9_mds/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[I 2023-11-17 17:20:27,747] A new study created in memory with name: no-name-a4fb30ec-040a-4bc2-9e45-155b397ba161\n","[I 2023-11-17 17:20:28,254] Trial 0 finished with value: 2631.901845726049 and parameters: {'learning_rate': 0.08197440749175473, 'n_estimators': 574, 'max_depth': 6, 'max_leaves': 9, 'min_child_weight': 5, 'reg_alpha': 0.9673564038996015, 'reg_lambda': 0.09820669376309132, 'min_frequency': 0.8018603712796477}. Best is trial 0 with value: 2631.901845726049.\n","[I 2023-11-17 17:20:29,242] Trial 1 finished with value: 2177.9751554574846 and parameters: {'learning_rate': 0.060885309625463256, 'n_estimators': 606, 'max_depth': 6, 'max_leaves': 48, 'min_child_weight': 2, 'reg_alpha': 0.30960447319461515, 'reg_lambda': 0.9079540077466299, 'min_frequency': 0.18498483412439337}. Best is trial 1 with value: 2177.9751554574846.\n","[I 2023-11-17 17:20:30,214] Trial 2 finished with value: 4412.986134580923 and parameters: {'learning_rate': 0.019635701927839904, 'n_estimators': 134, 'max_depth': 9, 'max_leaves': 64, 'min_child_weight': 5, 'reg_alpha': 0.5330602987538661, 'reg_lambda': 0.8794020557461902, 'min_frequency': 0.2934004821510383}. Best is trial 1 with value: 2177.9751554574846.\n","[I 2023-11-17 17:20:30,692] Trial 3 finished with value: 3046.0488414700444 and parameters: {'learning_rate': 0.043355733720661614, 'n_estimators': 707, 'max_depth': 3, 'max_leaves': 13, 'min_child_weight': 2, 'reg_alpha': 0.6820953023813442, 'reg_lambda': 0.9639243986805761, 'min_frequency': 0.45409686805072225}. Best is trial 1 with value: 2177.9751554574846.\n","[I 2023-11-17 17:20:31,088] Trial 4 finished with value: 2611.0091843377977 and parameters: {'learning_rate': 0.05170504867584292, 'n_estimators': 492, 'max_depth': 4, 'max_leaves': 20, 'min_child_weight': 2, 'reg_alpha': 0.3327931153595155, 'reg_lambda': 0.6910206996195489, 'min_frequency': 0.2804722556853273}. Best is trial 1 with value: 2177.9751554574846.\n","[I 2023-11-17 17:20:31,281] Trial 5 finished with value: 2831.299448383006 and parameters: {'learning_rate': 0.08276584689647232, 'n_estimators': 210, 'max_depth': 4, 'max_leaves': 78, 'min_child_weight': 2, 'reg_alpha': 0.6303835630942795, 'reg_lambda': 0.9460455286194741, 'min_frequency': 0.26344784197778537}. Best is trial 1 with value: 2177.9751554574846.\n","[I 2023-11-17 17:20:33,187] Trial 6 finished with value: 2294.07232146132 and parameters: {'learning_rate': 0.025410502155778256, 'n_estimators': 840, 'max_depth': 8, 'max_leaves': 36, 'min_child_weight': 5, 'reg_alpha': 0.969745948955058, 'reg_lambda': 0.8435000420609184, 'min_frequency': 0.5492408554174478}. Best is trial 1 with value: 2177.9751554574846.\n","[I 2023-11-17 17:20:34,523] Trial 7 finished with value: 2159.388422003374 and parameters: {'learning_rate': 0.06294703589733973, 'n_estimators': 530, 'max_depth': 9, 'max_leaves': 57, 'min_child_weight': 1, 'reg_alpha': 0.10524252085818897, 'reg_lambda': 0.8391481353085176, 'min_frequency': 0.8865100631109258}. Best is trial 7 with value: 2159.388422003374.\n","[I 2023-11-17 17:20:35,130] Trial 8 finished with value: 2255.903270862152 and parameters: {'learning_rate': 0.0964798633537203, 'n_estimators': 532, 'max_depth': 5, 'max_leaves': 73, 'min_child_weight': 5, 'reg_alpha': 0.3825242291436415, 'reg_lambda': 0.5951412356839362, 'min_frequency': 0.14260148902509284}. Best is trial 7 with value: 2159.388422003374.\n","[I 2023-11-17 17:20:35,642] Trial 9 finished with value: 2438.968508479261 and parameters: {'learning_rate': 0.08570184631980145, 'n_estimators': 559, 'max_depth': 4, 'max_leaves': 15, 'min_child_weight': 1, 'reg_alpha': 0.9790200997396965, 'reg_lambda': 0.36526623202322483, 'min_frequency': 0.925974139577977}. Best is trial 7 with value: 2159.388422003374.\n","[I 2023-11-17 17:20:37,743] Trial 10 finished with value: 2280.036502543909 and parameters: {'learning_rate': 0.01020312221263825, 'n_estimators': 979, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 1, 'reg_alpha': 0.022071705722580423, 'reg_lambda': 0.47362280996087375, 'min_frequency': 0.9926488225967768}. Best is trial 7 with value: 2159.388422003374.\n","[I 2023-11-17 17:20:38,262] Trial 11 finished with value: 2243.9774544074344 and parameters: {'learning_rate': 0.062014443432899476, 'n_estimators': 318, 'max_depth': 7, 'max_leaves': 47, 'min_child_weight': 3, 'reg_alpha': 0.10593191148595449, 'reg_lambda': 0.7465817311240537, 'min_frequency': 0.03146823557118328}. Best is trial 7 with value: 2159.388422003374.\n","[I 2023-11-17 17:20:38,892] Trial 12 finished with value: 2202.793455721307 and parameters: {'learning_rate': 0.06605638031184853, 'n_estimators': 357, 'max_depth': 7, 'max_leaves': 52, 'min_child_weight': 3, 'reg_alpha': 0.16856776286176545, 'reg_lambda': 0.9767370780921074, 'min_frequency': 0.7232843385678991}. Best is trial 7 with value: 2159.388422003374.\n","[I 2023-11-17 17:20:39,905] Trial 13 finished with value: 2269.968131379422 and parameters: {'learning_rate': 0.036824960851778346, 'n_estimators': 701, 'max_depth': 10, 'max_leaves': 36, 'min_child_weight': 1, 'reg_alpha': 0.22686652106852637, 'reg_lambda': 0.7683086213480506, 'min_frequency': 0.5965261684024112}. Best is trial 7 with value: 2159.388422003374.\n","[I 2023-11-17 17:20:40,955] Trial 14 finished with value: 2195.6043179650824 and parameters: {'learning_rate': 0.06290096601187364, 'n_estimators': 399, 'max_depth': 8, 'max_leaves': 57, 'min_child_weight': 2, 'reg_alpha': 0.03569159824043111, 'reg_lambda': 0.8062530290061892, 'min_frequency': 0.42555674077971767}. Best is trial 7 with value: 2159.388422003374.\n","[I 2023-11-17 17:20:42,333] Trial 15 finished with value: 2227.0962572308854 and parameters: {'learning_rate': 0.05024993009943872, 'n_estimators': 689, 'max_depth': 6, 'max_leaves': 38, 'min_child_weight': 4, 'reg_alpha': 0.2337327427022765, 'reg_lambda': 0.6521650186123981, 'min_frequency': 0.6558444711873629}. Best is trial 7 with value: 2159.388422003374.\n","[I 2023-11-17 17:20:44,109] Trial 16 finished with value: 2065.251672305971 and parameters: {'learning_rate': 0.06863532435280181, 'n_estimators': 850, 'max_depth': 8, 'max_leaves': 91, 'min_child_weight': 1, 'reg_alpha': 0.3287823583918645, 'reg_lambda': 0.9902605957275092, 'min_frequency': 0.8012497213479349}. Best is trial 16 with value: 2065.251672305971.\n","[I 2023-11-17 17:20:46,246] Trial 17 finished with value: 2096.1793919441125 and parameters: {'learning_rate': 0.073033617896095, 'n_estimators': 974, 'max_depth': 9, 'max_leaves': 100, 'min_child_weight': 1, 'reg_alpha': 0.11896545593647423, 'reg_lambda': 0.976365794911167, 'min_frequency': 0.8197103243869824}. Best is trial 16 with value: 2065.251672305971.\n","[I 2023-11-17 17:20:48,204] Trial 18 finished with value: 2103.3195232593475 and parameters: {'learning_rate': 0.07494688625556223, 'n_estimators': 997, 'max_depth': 8, 'max_leaves': 100, 'min_child_weight': 4, 'reg_alpha': 0.43069237597496557, 'reg_lambda': 0.9626119727629509, 'min_frequency': 0.7620603035039477}. Best is trial 16 with value: 2065.251672305971.\n","[I 2023-11-17 17:20:49,887] Trial 19 finished with value: 2100.134316478297 and parameters: {'learning_rate': 0.0996515795171467, 'n_estimators': 841, 'max_depth': 9, 'max_leaves': 87, 'min_child_weight': 1, 'reg_alpha': 0.2403952358831255, 'reg_lambda': 0.9881981578453268, 'min_frequency': 0.8097606796206869}. Best is trial 16 with value: 2065.251672305971.\n","[I 2023-11-17 17:20:51,649] Trial 20 finished with value: 2079.6307380415305 and parameters: {'learning_rate': 0.07369920466688713, 'n_estimators': 865, 'max_depth': 10, 'max_leaves': 86, 'min_child_weight': 3, 'reg_alpha': 0.006831233244505214, 'reg_lambda': 0.7575639145002315, 'min_frequency': 0.6332391477623728}. Best is trial 16 with value: 2065.251672305971.\n","[I 2023-11-17 17:20:53,406] Trial 21 finished with value: 2059.122385845018 and parameters: {'learning_rate': 0.07282982636193054, 'n_estimators': 851, 'max_depth': 10, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.12844433055906193, 'reg_lambda': 0.8292061847311486, 'min_frequency': 0.6368961446789255}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:20:55,284] Trial 22 finished with value: 2108.346062704351 and parameters: {'learning_rate': 0.07339986192773515, 'n_estimators': 849, 'max_depth': 10, 'max_leaves': 85, 'min_child_weight': 3, 'reg_alpha': 0.017421737676421634, 'reg_lambda': 0.8459964561168094, 'min_frequency': 0.6749127806214492}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:20:57,173] Trial 23 finished with value: 2120.691365478024 and parameters: {'learning_rate': 0.0909747570929459, 'n_estimators': 890, 'max_depth': 10, 'max_leaves': 73, 'min_child_weight': 4, 'reg_alpha': 0.17838881331661594, 'reg_lambda': 0.7350393775353922, 'min_frequency': 0.6125471115117225}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:20:58,620] Trial 24 finished with value: 2085.245292392375 and parameters: {'learning_rate': 0.07736353238294161, 'n_estimators': 766, 'max_depth': 8, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.0002024387584312025, 'reg_lambda': 0.8791227609467962, 'min_frequency': 0.7123566749551148}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:00,385] Trial 25 finished with value: 2120.15475666499 and parameters: {'learning_rate': 0.08943428009103555, 'n_estimators': 914, 'max_depth': 9, 'max_leaves': 79, 'min_child_weight': 4, 'reg_alpha': 0.10629747633649833, 'reg_lambda': 0.8031062372221671, 'min_frequency': 0.5510686562159632}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:01,649] Trial 26 finished with value: 2104.9296688333125 and parameters: {'learning_rate': 0.06806236659130746, 'n_estimators': 750, 'max_depth': 10, 'max_leaves': 66, 'min_child_weight': 3, 'reg_alpha': 0.2826792313544158, 'reg_lambda': 0.6329040081854304, 'min_frequency': 0.7073308526697547}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:02,939] Trial 27 finished with value: 2080.030265741585 and parameters: {'learning_rate': 0.07919323057598461, 'n_estimators': 781, 'max_depth': 7, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.16673553161588048, 'reg_lambda': 0.8952427088994369, 'min_frequency': 0.49678671689407233}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:04,201] Trial 28 finished with value: 2091.0404813320024 and parameters: {'learning_rate': 0.05349026839985664, 'n_estimators': 629, 'max_depth': 9, 'max_leaves': 82, 'min_child_weight': 4, 'reg_alpha': 0.0751019627555394, 'reg_lambda': 0.7231737105788576, 'min_frequency': 0.6360383770861995}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:04,522] Trial 29 finished with value: 13298.497707599765 and parameters: {'learning_rate': 0.08296849648352994, 'n_estimators': 899, 'max_depth': 8, 'max_leaves': 1, 'min_child_weight': 2, 'reg_alpha': 0.1796294805303803, 'reg_lambda': 0.7917178461914283, 'min_frequency': 0.7809896526422905}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:06,150] Trial 30 finished with value: 2102.1226725587903 and parameters: {'learning_rate': 0.07190233193027144, 'n_estimators': 798, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.34811227053861227, 'reg_lambda': 0.5658140588065848, 'min_frequency': 0.8622788927631736}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:07,675] Trial 31 finished with value: 2081.1076730565687 and parameters: {'learning_rate': 0.07633081065534755, 'n_estimators': 931, 'max_depth': 7, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.17581673497845582, 'reg_lambda': 0.8936685251047756, 'min_frequency': 0.4814266178830256}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:09,031] Trial 32 finished with value: 2068.84324861932 and parameters: {'learning_rate': 0.07984047764601078, 'n_estimators': 804, 'max_depth': 7, 'max_leaves': 73, 'min_child_weight': 3, 'reg_alpha': 0.27725783220783234, 'reg_lambda': 0.9106836705853543, 'min_frequency': 0.5378913929601187}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:09,852] Trial 33 finished with value: 2147.9424617365653 and parameters: {'learning_rate': 0.06848824064696996, 'n_estimators': 631, 'max_depth': 6, 'max_leaves': 70, 'min_child_weight': 2, 'reg_alpha': 0.3062927510620069, 'reg_lambda': 0.8950165379437859, 'min_frequency': 0.5724937813463077}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:10,685] Trial 34 finished with value: 2200.333780678865 and parameters: {'learning_rate': 0.07996206857191508, 'n_estimators': 840, 'max_depth': 5, 'max_leaves': 78, 'min_child_weight': 4, 'reg_alpha': 0.26344031943396395, 'reg_lambda': 0.9994135265761481, 'min_frequency': 0.4236220916127992}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:12,056] Trial 35 finished with value: 2128.2768273049755 and parameters: {'learning_rate': 0.05632746086848093, 'n_estimators': 727, 'max_depth': 9, 'max_leaves': 65, 'min_child_weight': 2, 'reg_alpha': 0.46623165516129006, 'reg_lambda': 0.9187974826341812, 'min_frequency': 0.6545489490704022}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:12,233] Trial 36 finished with value: 2821.2487955074193 and parameters: {'learning_rate': 0.08648342860666745, 'n_estimators': 61, 'max_depth': 8, 'max_leaves': 85, 'min_child_weight': 3, 'reg_alpha': 0.36554416363571185, 'reg_lambda': 0.9151138367352519, 'min_frequency': 0.7660106752719545}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:13,137] Trial 37 finished with value: 2195.056780625157 and parameters: {'learning_rate': 0.0698356366432463, 'n_estimators': 943, 'max_depth': 5, 'max_leaves': 73, 'min_child_weight': 2, 'reg_alpha': 0.3023348412688123, 'reg_lambda': 0.8311345439103114, 'min_frequency': 0.5354058094293134}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:14,327] Trial 38 finished with value: 2109.397995066755 and parameters: {'learning_rate': 0.079392440141543, 'n_estimators': 798, 'max_depth': 7, 'max_leaves': 96, 'min_child_weight': 5, 'reg_alpha': 0.06909218019565114, 'reg_lambda': 0.7763396803659185, 'min_frequency': 0.38943613601202604}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:15,179] Trial 39 finished with value: 2126.3677438982854 and parameters: {'learning_rate': 0.06540384330160631, 'n_estimators': 671, 'max_depth': 6, 'max_leaves': 82, 'min_child_weight': 2, 'reg_alpha': 0.5096449499572434, 'reg_lambda': 0.936148806982183, 'min_frequency': 0.6095810761700281}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:15,727] Trial 40 finished with value: 2760.633582746479 and parameters: {'learning_rate': 0.05888817097125917, 'n_estimators': 877, 'max_depth': 3, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.4269833682442128, 'reg_lambda': 0.8637447124853282, 'min_frequency': 0.5004624202763195}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:16,896] Trial 41 finished with value: 2080.239320198535 and parameters: {'learning_rate': 0.08272655626532993, 'n_estimators': 780, 'max_depth': 7, 'max_leaves': 78, 'min_child_weight': 3, 'reg_alpha': 0.18954584379832504, 'reg_lambda': 0.9253505661898734, 'min_frequency': 0.5090827469420228}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:18,084] Trial 42 finished with value: 2077.0493647103976 and parameters: {'learning_rate': 0.07800412678841145, 'n_estimators': 816, 'max_depth': 7, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.1381507277960174, 'reg_lambda': 0.8541725413384974, 'min_frequency': 0.5941339598096733}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:18,959] Trial 43 finished with value: 2141.793215183025 and parameters: {'learning_rate': 0.0922230927470476, 'n_estimators': 475, 'max_depth': 8, 'max_leaves': 96, 'min_child_weight': 4, 'reg_alpha': 0.13230735287712816, 'reg_lambda': 0.835417771165799, 'min_frequency': 0.5730716151174483}. Best is trial 21 with value: 2059.122385845018.\n","[I 2023-11-17 17:21:20,504] Trial 44 finished with value: 2034.7008926934 and parameters: {'learning_rate': 0.07030656263631437, 'n_estimators': 829, 'max_depth': 9, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.07298575769548347, 'reg_lambda': 0.7014716927898965, 'min_frequency': 0.6799054775385127}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:22,093] Trial 45 finished with value: 2119.6888754401407 and parameters: {'learning_rate': 0.08557885700890211, 'n_estimators': 816, 'max_depth': 9, 'max_leaves': 100, 'min_child_weight': 2, 'reg_alpha': 0.23444922352198494, 'reg_lambda': 0.680121798879526, 'min_frequency': 0.6911596892098794}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:23,205] Trial 46 finished with value: 2098.774137500786 and parameters: {'learning_rate': 0.06586258569060476, 'n_estimators': 731, 'max_depth': 8, 'max_leaves': 59, 'min_child_weight': 3, 'reg_alpha': 0.07593325527202366, 'reg_lambda': 0.704347498754622, 'min_frequency': 0.7581905789245093}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:24,256] Trial 47 finished with value: 2082.9089663305353 and parameters: {'learning_rate': 0.07071731319295917, 'n_estimators': 662, 'max_depth': 7, 'max_leaves': 90, 'min_child_weight': 2, 'reg_alpha': 0.33432811430088344, 'reg_lambda': 0.9480890208781528, 'min_frequency': 0.730380413609858}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:25,182] Trial 48 finished with value: 2087.081680676507 and parameters: {'learning_rate': 0.05986643240734969, 'n_estimators': 569, 'max_depth': 9, 'max_leaves': 70, 'min_child_weight': 5, 'reg_alpha': 0.2749988515244828, 'reg_lambda': 0.8476836201096601, 'min_frequency': 0.5854641048009819}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:25,554] Trial 49 finished with value: 2235.4663085118787 and parameters: {'learning_rate': 0.07789338314311656, 'n_estimators': 271, 'max_depth': 8, 'max_leaves': 43, 'min_child_weight': 4, 'reg_alpha': 0.1468129173119042, 'reg_lambda': 0.9993303741706557, 'min_frequency': 0.6611978607901031}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:27,015] Trial 50 finished with value: 2068.7058370732207 and parameters: {'learning_rate': 0.06432598531483338, 'n_estimators': 967, 'max_depth': 7, 'max_leaves': 96, 'min_child_weight': 1, 'reg_alpha': 0.06487461156145827, 'reg_lambda': 0.8104932827961887, 'min_frequency': 0.8421946004493202}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:28,538] Trial 51 finished with value: 2092.261759030747 and parameters: {'learning_rate': 0.06405748016269233, 'n_estimators': 952, 'max_depth': 7, 'max_leaves': 96, 'min_child_weight': 1, 'reg_alpha': 0.06269578552749369, 'reg_lambda': 0.7852599629857913, 'min_frequency': 0.8825474162311006}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:29,639] Trial 52 finished with value: 2145.7712145267437 and parameters: {'learning_rate': 0.07111849056474216, 'n_estimators': 902, 'max_depth': 6, 'max_leaves': 82, 'min_child_weight': 1, 'reg_alpha': 0.12644538269585787, 'reg_lambda': 0.8132507831327649, 'min_frequency': 0.8314713587361815}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:30,585] Trial 53 finished with value: 2291.8597766612697 and parameters: {'learning_rate': 0.06206577367593021, 'n_estimators': 964, 'max_depth': 7, 'max_leaves': 22, 'min_child_weight': 1, 'reg_alpha': 0.20646183386166403, 'reg_lambda': 0.870273074783492, 'min_frequency': 0.9365468919338014}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:32,172] Trial 54 finished with value: 2106.1965043843793 and parameters: {'learning_rate': 0.07510689682094733, 'n_estimators': 836, 'max_depth': 8, 'max_leaves': 96, 'min_child_weight': 1, 'reg_alpha': 0.05356250325553585, 'reg_lambda': 0.7366461958348185, 'min_frequency': 0.731842632698011}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:33,397] Trial 55 finished with value: 2140.2844580503856 and parameters: {'learning_rate': 0.06784898449263066, 'n_estimators': 989, 'max_depth': 6, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.097162752754595, 'reg_lambda': 0.9411095287914961, 'min_frequency': 0.6865286966265011}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:34,265] Trial 56 finished with value: 2244.2544657594003 and parameters: {'learning_rate': 0.0733976326075563, 'n_estimators': 873, 'max_depth': 7, 'max_leaves': 28, 'min_child_weight': 1, 'reg_alpha': 0.13455970378703888, 'reg_lambda': 0.8659694900518591, 'min_frequency': 0.7920020329954752}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:35,775] Trial 57 finished with value: 2080.1937056911784 and parameters: {'learning_rate': 0.08219987306068222, 'n_estimators': 921, 'max_depth': 8, 'max_leaves': 75, 'min_child_weight': 3, 'reg_alpha': 0.03462160701265647, 'reg_lambda': 0.9532670631561119, 'min_frequency': 0.8402127706382125}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:37,499] Trial 58 finished with value: 2149.907464644639 and parameters: {'learning_rate': 0.06499175399478449, 'n_estimators': 812, 'max_depth': 9, 'max_leaves': 100, 'min_child_weight': 2, 'reg_alpha': 0.20829658565434161, 'reg_lambda': 0.8170407789474854, 'min_frequency': 0.6495273397179646}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:38,853] Trial 59 finished with value: 2103.1491235826416 and parameters: {'learning_rate': 0.04803762547416819, 'n_estimators': 758, 'max_depth': 9, 'max_leaves': 82, 'min_child_weight': 3, 'reg_alpha': 0.24499114846037004, 'reg_lambda': 0.7759372899998574, 'min_frequency': 0.6044365810397413}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:40,172] Trial 60 finished with value: 2109.055921138812 and parameters: {'learning_rate': 0.05892844479792945, 'n_estimators': 702, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 1, 'reg_alpha': 0.14007927022454103, 'reg_lambda': 0.753702574700765, 'min_frequency': 0.7551979318393011}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:41,988] Trial 61 finished with value: 2104.7604248538105 and parameters: {'learning_rate': 0.07493329516771328, 'n_estimators': 854, 'max_depth': 10, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.000702455744027386, 'reg_lambda': 0.6940639940275483, 'min_frequency': 0.6247651435113186}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:44,690] Trial 62 finished with value: 2086.923142861073 and parameters: {'learning_rate': 0.07300923641662337, 'n_estimators': 875, 'max_depth': 10, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.09100399456110424, 'reg_lambda': 0.8787541033400417, 'min_frequency': 0.6947095329917568}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:47,441] Trial 63 finished with value: 2071.439613101788 and parameters: {'learning_rate': 0.07721323086858878, 'n_estimators': 921, 'max_depth': 10, 'max_leaves': 84, 'min_child_weight': 3, 'reg_alpha': 0.04065040155394878, 'reg_lambda': 0.7555890816416361, 'min_frequency': 0.6316963058752112}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:50,440] Trial 64 finished with value: 2108.437384397531 and parameters: {'learning_rate': 0.07859316331385717, 'n_estimators': 997, 'max_depth': 10, 'max_leaves': 84, 'min_child_weight': 3, 'reg_alpha': 0.04043970842527181, 'reg_lambda': 0.8114076612858772, 'min_frequency': 0.8038140137255616}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:52,363] Trial 65 finished with value: 2089.182821211121 and parameters: {'learning_rate': 0.06870748464061849, 'n_estimators': 917, 'max_depth': 9, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.10916448877270113, 'reg_lambda': 0.9663444398246772, 'min_frequency': 0.5740891032930859}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:53,865] Trial 66 finished with value: 2124.3042067509223 and parameters: {'learning_rate': 0.07615737488798419, 'n_estimators': 954, 'max_depth': 7, 'max_leaves': 80, 'min_child_weight': 4, 'reg_alpha': 0.04318125100554071, 'reg_lambda': 0.9122097070214783, 'min_frequency': 0.6330466181282861}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:54,639] Trial 67 finished with value: 2106.2112630208335 and parameters: {'learning_rate': 0.08051469339108477, 'n_estimators': 446, 'max_depth': 8, 'max_leaves': 76, 'min_child_weight': 2, 'reg_alpha': 0.20662864142770326, 'reg_lambda': 0.7555868929384665, 'min_frequency': 0.5420694381200761}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:56,373] Trial 68 finished with value: 2071.4112818185154 and parameters: {'learning_rate': 0.08501467832908621, 'n_estimators': 830, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.164877103000761, 'reg_lambda': 0.8395547761619495, 'min_frequency': 0.6752683752240721}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:58,145] Trial 69 finished with value: 2119.542210129265 and parameters: {'learning_rate': 0.08532002701157035, 'n_estimators': 897, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 4, 'reg_alpha': 0.08673677078593997, 'reg_lambda': 0.7978149597916901, 'min_frequency': 0.7276117554650988}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:21:59,710] Trial 70 finished with value: 2118.2770067671654 and parameters: {'learning_rate': 0.08932463408611573, 'n_estimators': 739, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.16231969199627436, 'reg_lambda': 0.71374284978722, 'min_frequency': 0.6663396198025087}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:01,168] Trial 71 finished with value: 2082.515007034394 and parameters: {'learning_rate': 0.0711562954072541, 'n_estimators': 824, 'max_depth': 9, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.16076923985627897, 'reg_lambda': 0.8403552989196748, 'min_frequency': 0.6021478245137429}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:02,448] Trial 72 finished with value: 2110.748106804892 and parameters: {'learning_rate': 0.07719911462967702, 'n_estimators': 786, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.11070459439404265, 'reg_lambda': 0.8955954703047996, 'min_frequency': 0.706898673962177}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:04,146] Trial 73 finished with value: 2095.8499614221787 and parameters: {'learning_rate': 0.08250060001932412, 'n_estimators': 853, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.024522279638878135, 'reg_lambda': 0.83792516612535, 'min_frequency': 0.6646320657187601}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:05,195] Trial 74 finished with value: 2104.573695100289 and parameters: {'learning_rate': 0.06685911905450938, 'n_estimators': 815, 'max_depth': 7, 'max_leaves': 85, 'min_child_weight': 3, 'reg_alpha': 0.0802235313408427, 'reg_lambda': 0.8692792879678393, 'min_frequency': 0.6359363521374696}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:06,448] Trial 75 finished with value: 2098.1068633480572 and parameters: {'learning_rate': 0.06990240352664846, 'n_estimators': 767, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 2, 'reg_alpha': 0.1476178640920257, 'reg_lambda': 0.9757796176794955, 'min_frequency': 0.7769457687495877}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:07,709] Trial 76 finished with value: 2052.4486374627977 and parameters: {'learning_rate': 0.06265399649796279, 'n_estimators': 922, 'max_depth': 9, 'max_leaves': 69, 'min_child_weight': 3, 'reg_alpha': 0.25334015473251204, 'reg_lambda': 0.7778326462957191, 'min_frequency': 0.5459204004182967}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:08,959] Trial 77 finished with value: 2119.1302954445423 and parameters: {'learning_rate': 0.06341468762598318, 'n_estimators': 937, 'max_depth': 9, 'max_leaves': 62, 'min_child_weight': 3, 'reg_alpha': 0.26458192427169686, 'reg_lambda': 0.7270465006422753, 'min_frequency': 0.551242208634017}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:10,294] Trial 78 finished with value: 2105.561956209916 and parameters: {'learning_rate': 0.0627976270394059, 'n_estimators': 977, 'max_depth': 9, 'max_leaves': 69, 'min_child_weight': 4, 'reg_alpha': 0.3008031849221602, 'reg_lambda': 0.7703051903145041, 'min_frequency': 0.5240505183907962}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:11,574] Trial 79 finished with value: 2106.0599603480255 and parameters: {'learning_rate': 0.056327494593947154, 'n_estimators': 894, 'max_depth': 9, 'max_leaves': 75, 'min_child_weight': 3, 'reg_alpha': 0.19531143802452128, 'reg_lambda': 0.6543546775080776, 'min_frequency': 0.6861430549610943}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:12,353] Trial 80 finished with value: 2180.6471391827527 and parameters: {'learning_rate': 0.06675809474349477, 'n_estimators': 931, 'max_depth': 5, 'max_leaves': 67, 'min_child_weight': 1, 'reg_alpha': 0.2384252511578798, 'reg_lambda': 0.9209307850481007, 'min_frequency': 0.7413866326544835}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:13,354] Trial 81 finished with value: 2098.5196317881246 and parameters: {'learning_rate': 0.07430011965998706, 'n_estimators': 859, 'max_depth': 8, 'max_leaves': 50, 'min_child_weight': 3, 'reg_alpha': 0.1214589675446869, 'reg_lambda': 0.7976730548080097, 'min_frequency': 0.5877617780392204}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:14,802] Trial 82 finished with value: 2057.6806986122465 and parameters: {'learning_rate': 0.07955028929487047, 'n_estimators': 883, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.062865796186111, 'reg_lambda': 0.8929938710100993, 'min_frequency': 0.5630761042801592}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:16,202] Trial 83 finished with value: 2109.5349450216927 and parameters: {'learning_rate': 0.08123788630735113, 'n_estimators': 886, 'max_depth': 10, 'max_leaves': 80, 'min_child_weight': 3, 'reg_alpha': 0.05830156977805104, 'reg_lambda': 0.8934493720266257, 'min_frequency': 0.5581910534630294}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:17,688] Trial 84 finished with value: 2066.4953763924696 and parameters: {'learning_rate': 0.07151150735557611, 'n_estimators': 917, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.01589792321963044, 'reg_lambda': 0.8268321978274634, 'min_frequency': 0.6191120804459423}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:19,222] Trial 85 finished with value: 2088.584300235004 and parameters: {'learning_rate': 0.07193899463766933, 'n_estimators': 968, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.17354924396755667, 'reg_lambda': 0.9415479704930907, 'min_frequency': 0.48172332075439867}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:20,549] Trial 86 finished with value: 2094.1565223043995 and parameters: {'learning_rate': 0.0683863193854548, 'n_estimators': 795, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 2, 'reg_alpha': 0.009064495215385847, 'reg_lambda': 0.8250220833494506, 'min_frequency': 0.5125553402222792}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:21,883] Trial 87 finished with value: 2055.597644133027 and parameters: {'learning_rate': 0.06184886880682736, 'n_estimators': 836, 'max_depth': 9, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.07236935674310874, 'reg_lambda': 0.8988217008765328, 'min_frequency': 0.532256908640334}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:22,940] Trial 88 finished with value: 2105.2987531307635 and parameters: {'learning_rate': 0.061981288875378696, 'n_estimators': 874, 'max_depth': 9, 'max_leaves': 55, 'min_child_weight': 3, 'reg_alpha': 0.06718463421230988, 'reg_lambda': 0.9813808449591984, 'min_frequency': 0.5367414634988336}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:24,181] Trial 89 finished with value: 2104.6916512093394 and parameters: {'learning_rate': 0.06514932539639838, 'n_estimators': 945, 'max_depth': 9, 'max_leaves': 62, 'min_child_weight': 4, 'reg_alpha': 0.09272522695084924, 'reg_lambda': 0.9026436523896681, 'min_frequency': 0.4650063231470797}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:25,502] Trial 90 finished with value: 2100.84287315691 and parameters: {'learning_rate': 0.060127027532402524, 'n_estimators': 904, 'max_depth': 9, 'max_leaves': 87, 'min_child_weight': 1, 'reg_alpha': 0.019548504840320287, 'reg_lambda': 0.9257811758306983, 'min_frequency': 0.6075216681475624}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:26,855] Trial 91 finished with value: 2090.697472104764 and parameters: {'learning_rate': 0.07138118004856643, 'n_estimators': 837, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.114560144855551, 'reg_lambda': 0.8463153711183088, 'min_frequency': 0.5793537507949764}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:28,288] Trial 92 finished with value: 2105.79278699541 and parameters: {'learning_rate': 0.06879990409166507, 'n_estimators': 851, 'max_depth': 9, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.06083484707888815, 'reg_lambda': 0.8790889488349793, 'min_frequency': 0.5639747500434629}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:29,416] Trial 93 finished with value: 2054.8689891628414 and parameters: {'learning_rate': 0.06602593569502847, 'n_estimators': 723, 'max_depth': 8, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.08537326982977791, 'reg_lambda': 0.7911898523098848, 'min_frequency': 0.6148754394654258}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:30,669] Trial 94 finished with value: 2035.5284912600603 and parameters: {'learning_rate': 0.06603956355430582, 'n_estimators': 759, 'max_depth': 8, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.08808553287013851, 'reg_lambda': 0.7858775820744834, 'min_frequency': 0.5202786168100865}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:31,819] Trial 95 finished with value: 2103.6444660803363 and parameters: {'learning_rate': 0.06450194502265635, 'n_estimators': 723, 'max_depth': 8, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.027808709638024353, 'reg_lambda': 0.7864180849352962, 'min_frequency': 0.5231613657378954}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:32,977] Trial 96 finished with value: 2080.1365808785004 and parameters: {'learning_rate': 0.06104675266469878, 'n_estimators': 757, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.09977412902942207, 'reg_lambda': 0.818256024034371, 'min_frequency': 0.4905296925583885}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:33,959] Trial 97 finished with value: 2076.8702601350287 and parameters: {'learning_rate': 0.06676146349869093, 'n_estimators': 614, 'max_depth': 8, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.07528804527935207, 'reg_lambda': 0.7463894659132008, 'min_frequency': 0.6173160804518955}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:34,990] Trial 98 finished with value: 2116.3275946368312 and parameters: {'learning_rate': 0.06974576257809532, 'n_estimators': 664, 'max_depth': 9, 'max_leaves': 83, 'min_child_weight': 5, 'reg_alpha': 0.047146069674202214, 'reg_lambda': 0.8547908169766856, 'min_frequency': 0.648937668302338}. Best is trial 44 with value: 2034.7008926934.\n","[I 2023-11-17 17:22:36,196] Trial 99 finished with value: 2080.6908277464263 and parameters: {'learning_rate': 0.05736889827968827, 'n_estimators': 777, 'max_depth': 8, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.12331380128582978, 'reg_lambda': 0.7900474779497385, 'min_frequency': 0.5604697319424619}. Best is trial 44 with value: 2034.7008926934.\n"]},{"name":"stdout","output_type":"stream","text":["Número de trials: 100\n","Mejores hiperparámetros: {'learning_rate': 0.07030656263631437, 'n_estimators': 829, 'max_depth': 9, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.07298575769548347, 'reg_lambda': 0.7014716927898965, 'min_frequency': 0.6799054775385127}\n","MAE óptimo: 2034.7008926934\n"]}],"source":["import optuna\n","\n","# Define la función objetivo para Optuna\n","def objective(trial):\n","    # Definir los rangos de búsqueda para los hiperparámetros\n","    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1)\n","    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n","    max_depth = trial.suggest_int('max_depth', 3, 10)\n","    max_leaves = trial.suggest_int('max_leaves', 0, 100)\n","    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n","    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n","    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n","    \n","    min_frequency = trial.suggest_float('min_frequency', 0.0, 1.0)\n","\n","    # Crear un nuevo pipeline con los hiperparámetros sugeridos por Optuna\n","    xgb_model = XGBRegressor(\n","        learning_rate=learning_rate,\n","        n_estimators=n_estimators,\n","        max_depth=max_depth,\n","        max_leaves=max_leaves,\n","        min_child_weight=min_child_weight,\n","        reg_alpha=reg_alpha,\n","        reg_lambda=reg_lambda\n","    )\n","\n","    # Modificar el valor de min_frequency del OneHotEncoder en el ColumnTransformer\n","    for name, transformer, columns in preprocessor.transformers_:\n","        if isinstance(transformer, OneHotEncoder):\n","            transformer.set_params(min_frequency=min_frequency)\n","\n","    pipeline_xgb = Pipeline(steps=[\n","        ('date', date_transformer),\n","        ('preprocessor', preprocessor),\n","        ('regressor', xgb_model)\n","    ])\n","\n","    pipeline_xgb.fit(train_X, train_Y)\n","\n","    # Calcular MAE en datos de validación\n","    y_pred = pipeline_xgb.predict(val_X)\n","    mae = mean_absolute_error(val_Y, y_pred)\n","    joblib.dump(xgb_model, 'xgb_model_opti.pkl')\n","    return mae\n","\n","# Crear un estudio de Optuna\n","study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=314159))\n","study.optimize(objective, n_trials=100, timeout=300)\n","\n","# Obtener los mejores hiperparámetros encontrados\n","best_params = study.best_params\n","mae_optuna_1 = study.best_value\n","num_trials = len(study.trials)\n","\n","\n","print(\"Número de trials:\", num_trials)\n","print(\"Mejores hiperparámetros:\", best_params)\n","print(\"MAE óptimo:\", mae_optuna_1)"]},{"cell_type":"markdown","metadata":{"cell_id":"5195ccfc37e044ad9453f6eb2754f631","deepnote_cell_type":"markdown"},"source":["## 1.4 Optimización de Hiperparámetros con Optuna y Prunners (1.7)\n","\n","<p align=\"center\">\n","  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n","</p>\n","\n","Después de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en sí mismo. Después de leer un par de post de personas de dudosa reputación en la *deepweb*, usted llega a la conclusión que puede cumplir este objetivo mediante la implementación de **Prunning**.\n","\n","Vuelva a optimizar los mismos hiperparámetros que la sección pasada, pero esta vez utilizando **Prunning** en la optimización. En particular, usted debe:\n","\n","- Responder: ¿Qué es prunning? ¿De qué forma debería impactar en el entrenamiento?\n","- Utilizar `optuna.integration.XGBoostPruningCallback` como método de **Prunning**\n","- Fijar nuevamente el tiempo de entrenamiento a 5 minutos\n","- Reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto?\n","- Guardar su modelo en un archivo .pkl\n","\n","Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n","\n","```\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","```\n","\n","De implementar la opción anterior, pueden especificar `show_progress_bar = True` en el método `optimize` para *más sabor*.\n","\n","Hint: Si quieren especificar parámetros del método .fit() del modelo a través del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n","\n","Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementación"]},{"cell_type":"code","execution_count":16,"metadata":{"cell_id":"eeaa967cd8f6426d8c54f276c17dce79","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["Best trial: 25. Best value: 2052.66: 100%|██████████| 100/100 [02:49<00:00,  1.70s/it, 169.78/300 seconds]"]},{"name":"stdout","output_type":"stream","text":["Trial 99 finished with value: 2141.9995048415494 and parameters: {'learning_rate': 0.09238247956379142, 'n_estimators': 749, 'max_depth': 8, 'max_leaves': 96, 'min_child_weight': 4, 'reg_alpha': 0.8336477572469388, 'reg_lambda': 0.13298038521888692, 'min_frequency': 0.6427010241443947}.\n","Best is trial 25 with value: 2052.6617111523306.\n","Número de trials con Prunning: 100\n","Mejores hiperparámetros con Prunning: {'learning_rate': 0.07773388801310545, 'n_estimators': 653, 'max_depth': 8, 'max_leaves': 80, 'min_child_weight': 3, 'reg_alpha': 0.7773210705472171, 'reg_lambda': 0.018995513864300692, 'min_frequency': 0.7774500546927109}\n","MAE óptimo con Prunning: 2052.6617111523306\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import optuna\n","from optuna.integration import XGBoostPruningCallback\n","import time\n","from IPython.display import clear_output\n","\n","# Callback para actualizar la salida después de cada trial\n","def print_callback(study, trial):\n","    clear_output(wait=True)\n","    print(f\"Trial {trial.number} finished with value: {trial.value} and parameters: {trial.params}.\")\n","    print(f\"Best is trial {study.best_trial.number} with value: {study.best_value}.\")\n","\n","\n","# Define la función objetivo para Optuna con Prunning\n","def objective_with_prunning(trial):\n","    # Definir los rangos de búsqueda para los hiperparámetros\n","    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1)\n","    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n","    max_depth = trial.suggest_int('max_depth', 3, 10)\n","    max_leaves = trial.suggest_int('max_leaves', 0, 100)\n","    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n","    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n","    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n","    \n","    min_frequency = trial.suggest_float('min_frequency', 0.0, 1.0)\n","\n","    # Ajustar el valor de min_frequency del OneHotEncoder en el ColumnTransformer\n","    for name, transformer, columns in preprocessor.transformers_:\n","        if isinstance(transformer, OneHotEncoder):\n","            transformer.set_params(min_frequency=min_frequency)\n","\n","    # Crear un pipeline solo para el preprocesamiento\n","    pipeline_preprocess = Pipeline(steps=[\n","        ('date', date_transformer),\n","        ('preprocessor', preprocessor)\n","    ])\n","\n","    # Transformar el conjunto de validación\n","    X_valid_transformed = pipeline_preprocess.transform(val_X)\n","\n","    # Crear el modelo XGBRegressor con los hiperparámetros sugeridos por Optuna\n","    xgb_model = XGBRegressor(\n","        learning_rate=learning_rate,\n","        n_estimators=n_estimators,\n","        max_depth=max_depth,\n","        max_leaves=max_leaves,\n","        min_child_weight=min_child_weight,\n","        reg_alpha=reg_alpha,\n","        reg_lambda=reg_lambda\n","    )\n","\n","    # Implementar Prunning\n","    pruning_callback = XGBoostPruningCallback(trial, \"validation_0-rmse\")\n","\n","    # Entrenar el modelo con los datos de entrenamiento transformados y validación\n","    xgb_model.fit(pipeline_preprocess.transform(train_X), train_Y, \n","                  eval_set=[(X_valid_transformed, val_Y)],\n","                  early_stopping_rounds=10,\n","                  callbacks=[pruning_callback])\n","\n","    # Calcular MAE en datos de validación transformados\n","    y_pred = xgb_model.predict(X_valid_transformed)\n","    mae = mean_absolute_error(val_Y, y_pred)\n","\n","    return mae\n","\n","\n","\n","# Crear un estudio de Optuna con Prunning\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","import warnings\n","warnings.filterwarnings('ignore', category=UserWarning, module='xgboost.sklearn')\n","study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=314159))\n","study.optimize(objective_with_prunning, n_trials=100, timeout=300, show_progress_bar=True, callbacks=[print_callback])\n","\n","# Obtener los mejores hiperparámetros encontrados\n","best_params = study.best_params\n","mae_optuna_2 = study.best_value\n","num_trials = len(study.trials)\n","\n","# After the optimization is complete:\n","joblib.dump(study, 'study_prunning.pkl')\n","\n","print(\"Número de trials con Prunning:\", num_trials)\n","print(\"Mejores hiperparámetros con Prunning:\", best_params)\n","print(\"MAE óptimo con Prunning:\", mae_optuna_2)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"8a081778cc704fc6bed05393a5419327","deepnote_cell_type":"markdown"},"source":["## 1.5 Visualizaciones (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n","</p>\n","\n","\n","Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n","\n","A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n","\n","- Gráfico de historial de optimización\n","- Gráfico de coordenadas paralelas\n","- Gráfico de importancia de hiperparámetros\n","\n","Comente sus resultados: ¿Desde qué *trial* se empiezan a observar mejoras notables en sus resultados? ¿Qué tendencias puede observar a partir del gráfico de coordenadas paralelas? ¿Cuáles son los hiperparámetros con mayor importancia para la optimización de su modelo?"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"0e706dc9a8d946eda7a9eb1f0463c6d7","deepnote_cell_type":"code"},"outputs":[],"source":["# Inserte su código acá"]},{"cell_type":"markdown","metadata":{"cell_id":"ac8a20f445d045a3becf1a518d410a7d","deepnote_cell_type":"markdown"},"source":["## 1.6 Síntesis de resultados (0.3)\n","\n","Finalmente, genere una tabla resumen del MAE obtenido en los 5 modelos entrenados (desde Baseline hasta XGBoost con Constraints, Optuna y Prunning) y compare sus resultados. ¿Qué modelo obtiene el mejor rendimiento? \n","\n","Por último, cargue el mejor modelo, prediga sobre el conjunto de test y reporte su MAE. ¿Existen diferencias con respecto a las métricas obtenidas en el conjunto de validación? ¿Porqué puede ocurrir esto?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calcula el MAE para cada modelo\n","mae_baseline = mae_dummy\n","mae_xgboost = mae_xgb  \n","mae_optuna = mae_optuna_1\n","mae_constraints = mae_xgb_monotone \n","mae_pruning = 3.5  \n","\n","# Crea un DataFrame con los valores de MAE\n","data = {\n","    'Modelo': ['Baseline', 'XGBoost', 'XGBoost (Optuna)', 'XGBoost (Constraints)', 'XGBoost (Optuna, Pruning)'],\n","    'MAE': [mae_baseline, mae_xgboost, mae_optuna, mae_constraints, mae_pruning]\n","}\n","\n","tabla = pd.DataFrame(data)\n","\n","# Imprime la tabla resumen\n","display(tabla)"]},{"cell_type":"markdown","metadata":{"cell_id":"5c4654d12037494fbd385b4dc6bd1059","deepnote_cell_type":"markdown"},"source":["# Conclusión\n","Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n","</p>"]},{"cell_type":"markdown","metadata":{"cell_id":"5025de06759f4903a26916c80323bf25","deepnote_cell_type":"markdown"},"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"f63d38450a6b464c9bb6385cf11db4d9","deepnote_persisted_session":{"createdAt":"2023-11-09T16:18:30.203Z"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
